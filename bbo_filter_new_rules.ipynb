{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Filter and Merge New Rules\n",
        "\n",
        "Takes 5m\n",
        "\n",
        "This notebook:\n",
        "1. Reads `bbo_bt_new_rules.parquet`\n",
        "2. Filters criteria based on configurable thresholds (lift, pos count/pct, neg count/pct)\n",
        "3. Creates `Accepted_Criteria` and `Rejected_Criteria` columns\n",
        "4. Creates `Merged_Rules` by merging BT base criteria for the **correct seat** (`Agg_Expr_Seat_{seat}`) with accepted criteria\n",
        "5. Ensures merged numeric inequalities (HCP / Total_Points / SL_*) do **not** contradict the BT base bounds\n",
        "6. Create analytical reports and exports to Excel file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-07 11:04:39\n",
            "Threshold Configuration:\n",
            "  MIN_LIFT: 1.5\n",
            "  MIN_POS_RATE: 50%\n",
            "  MIN_POS_COUNT: 50\n",
            "  MAX_NEG_RATE: 80%\n",
            "  HIGH_CONFIDENCE_POS_RATE: 98%\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "import re\n",
        "from pathlib import Path\n",
        "import time\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import polars as pl\n",
        "\n",
        "program_start_time = time.time()\n",
        "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
        "\n",
        "# Paths\n",
        "INPUT_FILE = Path(\"E:/bridge/data/bbo/bidding/bbo_bt_new_rules.parquet\")\n",
        "BT_SEAT1_FILE = Path(\"E:/bridge/data/bbo/bidding/bbo_bt_seat1.parquet\")\n",
        "OUTPUT_FILE = Path(\"E:/bridge/data/bbo/bidding/bbo_bt_merged_rules.parquet\")\n",
        "\n",
        "# =============================================================================\n",
        "# THRESHOLD CONFIGURATION\n",
        "# =============================================================================\n",
        "# A criterion is ACCEPTED if ALL conditions are met:\n",
        "#   - lift >= MIN_LIFT\n",
        "#   - pos_rate >= MIN_POS_RATE (as decimal, e.g. 0.50 = 50%)\n",
        "#   - pos_count >= MIN_POS_COUNT (absolute count based on pos_rate * group pos_count)\n",
        "#   - neg_rate <= MAX_NEG_RATE (optional upper bound on negative rate)\n",
        "#\n",
        "# BUG FIX (2026-01-07): Changed MIN_POS_RATE from 0.10 to 0.50.\n",
        "# The old 10% threshold accepted criteria like SL_S <= 1 for 1H openers even though\n",
        "# only 21% of 1H hands have spade length <= 1. Since these criteria are enforced as\n",
        "# HARD REQUIREMENTS in Bidding Arena, accepting criteria with low pos_rate causes\n",
        "# 79%+ of valid hands to be incorrectly rejected. A 50% threshold ensures we only\n",
        "# accept criteria that are true for the MAJORITY of positive cases.\n",
        "#\n",
        "# FIX #2 (2026-01-07): Added HIGH_CONFIDENCE_POS_RATE = 0.98 and logic to prefer\n",
        "# the MOST RESTRICTIVE bound when multiple bounds pass the high-confidence threshold.\n",
        "# Example: For 1H, both SL_H >= 4 (99.92%) and SL_H >= 5 (99.16%) pass 50%, but\n",
        "# SL_H >= 5 is the correct requirement. Since SL_H >= 5 passes 98% and is more\n",
        "# restrictive (higher value for >=), we should prefer it over SL_H >= 4.\n",
        "\n",
        "MIN_LIFT = 1.5          # Minimum lift to accept criterion\n",
        "MIN_POS_RATE = 0.50     # Minimum positive rate (50%) - must be true for majority of positives\n",
        "MIN_POS_COUNT = 50      # Minimum absolute positive count for criterion\n",
        "MAX_NEG_RATE = 0.80     # Maximum negative rate (reject if too common in negatives)\n",
        "HIGH_CONFIDENCE_POS_RATE = 0.98  # Threshold for preferring most restrictive bound\n",
        "\n",
        "# Sample auctions for inspection (reused across cells)\n",
        "SAMPLE_AUCTIONS = [\"1n\", \"1s\", \"1h\", \"1d\", \"1c\"]\n",
        "\n",
        "# Pre-compiled regex for parsing inequality criteria\n",
        "INEQUALITY_RE = re.compile(r'(\\w+)\\s*(>=|<=|>|<|==|!=)\\s*(\\d+)')\n",
        "\n",
        "print(\"Threshold Configuration:\")\n",
        "print(f\"  MIN_LIFT: {MIN_LIFT}\")\n",
        "print(f\"  MIN_POS_RATE: {MIN_POS_RATE:.0%}\")\n",
        "print(f\"  MIN_POS_COUNT: {MIN_POS_COUNT}\")\n",
        "print(f\"  MAX_NEG_RATE: {MAX_NEG_RATE:.0%}\")\n",
        "print(f\"  HIGH_CONFIDENCE_POS_RATE: {HIGH_CONFIDENCE_POS_RATE:.0%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading E:\\bridge\\data\\bbo\\bidding\\bbo_bt_new_rules.parquet...\n",
            "  Loaded 66,814 rows\n",
            "  Columns: ['step_auction', 'bt_index', 'seat', 'prefix', 'next_bid', 'pos_count', 'neg_count', 'base_rules', 'discovered_rules', 'criteria_with_metrics', 'New_Rules', 'top_lift', 'bt_row_found']\n",
            "Loading BT base criteria from E:\\bridge\\data\\bbo\\bidding\\bbo_bt_seat1.parquet...\n",
            "Preview:\n",
            "shape: (5, 6)\n",
            "┌──────────────┬──────┬───────────┬────────────┬─────────────────────────────────┬───────────┐\n",
            "│ step_auction ┆ seat ┆ bt_index  ┆ bt_auction ┆ base_rules                      ┆ pos_count │\n",
            "│ ---          ┆ ---  ┆ ---       ┆ ---        ┆ ---                             ┆ ---       │\n",
            "│ str          ┆ i64  ┆ i64       ┆ str        ┆ list[str]                       ┆ i64       │\n",
            "╞══════════════╪══════╪═══════════╪════════════╪═════════════════════════════════╪═══════════╡\n",
            "│ 1d           ┆ 1    ┆ 151867501 ┆ null       ┆ [\"HCP <= 21\", \"HCP >= 11\", … \"… ┆ 3507593   │\n",
            "│ 1c           ┆ 1    ┆ 0         ┆ null       ┆ [\"HCP <= 21\", \"HCP >= 11\", … \"… ┆ 3446023   │\n",
            "│ 1n           ┆ 1    ┆ 408062490 ┆ null       ┆ [\"HCP <= 17\", \"HCP >= 15\", … \"… ┆ 2518162   │\n",
            "│ 1s           ┆ 1    ┆ 351032258 ┆ null       ┆ [\"HCP <= 21\", \"HCP >= 11\", … \"… ┆ 2497723   │\n",
            "│ 1h           ┆ 1    ┆ 280296284 ┆ null       ┆ [\"HCP <= 21\", \"HCP >= 11\", … \"… ┆ 2363106   │\n",
            "└──────────────┴──────┴───────────┴────────────┴─────────────────────────────────┴───────────┘\n"
          ]
        }
      ],
      "source": [
        "# takes 3m45s\n",
        "# Load data\n",
        "print(f\"Loading {INPUT_FILE}...\")\n",
        "if not INPUT_FILE.exists():\n",
        "    raise FileNotFoundError(f\"Input file not found: {INPUT_FILE}\")\n",
        "\n",
        "if not BT_SEAT1_FILE.exists():\n",
        "    raise FileNotFoundError(f\"BT seat-1 file not found: {BT_SEAT1_FILE}\")\n",
        "\n",
        "df = pl.read_parquet(INPUT_FILE)\n",
        "print(f\"  Loaded {df.height:,} rows\")\n",
        "print(f\"  Columns: {df.columns}\")\n",
        "\n",
        "# Join in BT base criteria for the CORRECT SEAT.\n",
        "# IMPORTANT: Some rows in bbo_bt_new_rules.parquet have base_rules=[], even for real auctions.\n",
        "# We load ALL Agg_Expr_Seat_X columns and select the appropriate one based on each row's seat.\n",
        "# \n",
        "# BUG FIX (2026-01-06): Previously we always used Agg_Expr_Seat_1, which caused opener's\n",
        "# criteria (e.g., HCP >= 15) to be merged into other seats' Merged_Rules.\n",
        "print(f\"Loading BT base criteria from {BT_SEAT1_FILE}...\")\n",
        "bt = pl.read_parquet(BT_SEAT1_FILE, columns=[\n",
        "    \"bt_index\", \n",
        "    \"Agg_Expr_Seat_1\", \"Agg_Expr_Seat_2\", \"Agg_Expr_Seat_3\", \"Agg_Expr_Seat_4\",\n",
        "    \"is_completed_auction\", \"Auction\"\n",
        "])\n",
        "if \"is_completed_auction\" in bt.columns:\n",
        "    bt = bt.filter(pl.col(\"is_completed_auction\") == True)\n",
        "\n",
        "bt = bt.select([\n",
        "    pl.col(\"bt_index\").cast(pl.Int64),\n",
        "    pl.col(\"Agg_Expr_Seat_1\").alias(\"bt_agg_seat_1\"),\n",
        "    pl.col(\"Agg_Expr_Seat_2\").alias(\"bt_agg_seat_2\"),\n",
        "    pl.col(\"Agg_Expr_Seat_3\").alias(\"bt_agg_seat_3\"),\n",
        "    pl.col(\"Agg_Expr_Seat_4\").alias(\"bt_agg_seat_4\"),\n",
        "    pl.col(\"Auction\").alias(\"bt_auction\"),\n",
        "])\n",
        "\n",
        "# Normalize types and join\n",
        "if \"bt_index\" in df.columns:\n",
        "    df = df.with_columns(pl.col(\"bt_index\").cast(pl.Int64))\n",
        "\n",
        "if \"base_rules\" not in df.columns:\n",
        "    df = df.with_columns(pl.lit([]).cast(pl.List(pl.Utf8)).alias(\"base_rules\"))\n",
        "\n",
        "# Join BT data\n",
        "df = df.join(bt, on=\"bt_index\", how=\"left\")\n",
        "\n",
        "# Select the correct Agg_Expr_Seat_X based on each row's seat column.\n",
        "# This ensures we use seat 1's criteria for seat 1, seat 2's for seat 2, etc.\n",
        "df = df.with_columns(\n",
        "    pl.when(pl.col(\"seat\") == 1)\n",
        "    .then(pl.col(\"bt_agg_seat_1\"))\n",
        "    .when(pl.col(\"seat\") == 2)\n",
        "    .then(pl.col(\"bt_agg_seat_2\"))\n",
        "    .when(pl.col(\"seat\") == 3)\n",
        "    .then(pl.col(\"bt_agg_seat_3\"))\n",
        "    .when(pl.col(\"seat\") == 4)\n",
        "    .then(pl.col(\"bt_agg_seat_4\"))\n",
        "    .otherwise(pl.col(\"bt_agg_seat_1\"))  # Fallback to seat 1 if seat is invalid\n",
        "    .alias(\"bt_base_rules\")\n",
        ")\n",
        "\n",
        "# Override base_rules with BT base when available.\n",
        "df = df.with_columns(\n",
        "    pl.when(\n",
        "        pl.col(\"bt_base_rules\").is_not_null() & (pl.col(\"bt_base_rules\").list.len() > 0)\n",
        "    )\n",
        "    .then(pl.col(\"bt_base_rules\"))\n",
        "    .otherwise(pl.col(\"base_rules\"))\n",
        "    .alias(\"base_rules\")\n",
        ")\n",
        "\n",
        "# Drop intermediate columns\n",
        "df = df.drop([\"bt_agg_seat_1\", \"bt_agg_seat_2\", \"bt_agg_seat_3\", \"bt_agg_seat_4\", \"bt_base_rules\"])\n",
        "\n",
        "print(\"Preview:\")\n",
        "print(df.select([c for c in [\"step_auction\", \"seat\", \"bt_index\", \"bt_auction\", \"base_rules\", \"pos_count\"] if c in df.columns]).head(5))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inspecting criteria_with_metrics for selected auctions:\n",
            "================================================================================\n",
            "\n",
            "1n (seat 1, 2,518,162 deals):\n",
            "  Base rules: ['HCP <= 17', 'HCP >= 15', 'SL_C <= 5', 'SL_C >= 2', 'SL_D <= 5', 'SL_D >= 2', 'SL_H <= 5', 'SL_H >= 2', 'SL_S <= 5', 'SL_S >= 2', 'Total_Points <= 18']\n",
            "  Discovered criteria with metrics:\n",
            "    HCP >= 15                  lift=    2.64  pos=87.78%  neg=33.23%\n",
            "    HCP >= 16                  lift=    2.17  pos=54.79%  neg=25.29%\n",
            "    HCP >= 14                  lift=    2.00  pos=96.92%  neg=48.43%\n",
            "    Total_Points >= 16         lift=    1.85  pos=83.28%  neg=45.13%\n",
            "    Total_Points >= 15         lift=    1.59  pos=96.38%  neg=60.44%\n",
            "    Total_Points >= 17         lift=    1.54  pos=53.85%  neg=34.93%\n",
            "\n",
            "1s (seat 1, 2,497,723 deals):\n",
            "  Base rules: ['HCP <= 21', 'HCP >= 11', 'SL_S >= 5', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Discovered criteria with metrics:\n",
            "    SL_S >= 5                  lift=   22.26  pos=99.32%  neg= 4.46%\n",
            "    SL_S >= 6                  lift=   13.55  pos=32.57%  neg= 2.40%\n",
            "    SL_S >= 4                  lift=    3.23  pos=99.93%  neg=30.91%\n",
            "    SL_H <= 1                  lift=    2.50  pos=20.62%  neg= 8.26%\n",
            "    SL_D <= 1                  lift=    2.40  pos=20.15%  neg= 8.41%\n",
            "    SL_C <= 1                  lift=    2.35  pos=20.44%  neg= 8.71%\n",
            "\n",
            "1h (seat 1, 2,363,106 deals):\n",
            "  Base rules: ['HCP <= 21', 'HCP >= 11', 'SL_H >= 5', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Discovered criteria with metrics:\n",
            "    SL_H >= 5                  lift=   18.68  pos=99.16%  neg= 5.31%\n",
            "    SL_H >= 6                  lift=   13.89  pos=33.74%  neg= 2.43%\n",
            "    SL_H >= 4                  lift=    3.21  pos=99.92%  neg=31.17%\n",
            "    SL_S <= 1                  lift=    2.69  pos=21.59%  neg= 8.03%\n",
            "    SL_D <= 1                  lift=    2.17  pos=18.93%  neg= 8.74%\n",
            "    SL_C <= 1                  lift=    2.14  pos=19.33%  neg= 9.02%\n",
            "\n",
            "1d (seat 1, 3,507,593 deals):\n",
            "  Base rules: ['HCP <= 21', 'HCP >= 11', 'SL_D >= 3', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Discovered criteria with metrics:\n",
            "    SL_D >= 6                  lift=    8.14  pos=21.21%  neg= 2.61%\n",
            "    SL_D >= 5                  lift=    6.98  pos=56.52%  neg= 8.09%\n",
            "    SL_D >= 4                  lift=    3.58  pos=94.14%  neg=26.29%\n",
            "    SL_D >= 3                  lift=    1.64  pos=99.35%  neg=60.42%\n",
            "    SL_S <= 1                  lift=    1.61  pos=14.28%  neg= 8.84%\n",
            "    SL_H <= 1                  lift=    1.59  pos=14.37%  neg= 9.02%\n",
            "\n",
            "1c (seat 1, 3,446,023 deals):\n",
            "  Base rules: ['HCP <= 21', 'HCP >= 11', 'SL_C >= 3', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Discovered criteria with metrics:\n",
            "    SL_C >= 6                  lift=   15.38  pos=21.05%  neg= 1.37%\n",
            "    SL_C >= 5                  lift=    6.86  pos=52.26%  neg= 7.62%\n",
            "    SL_C >= 4                  lift=    2.89  pos=81.81%  neg=28.32%\n",
            "    SL_C >= 3                  lift=    1.65  pos=98.60%  neg=59.67%\n",
            "    SL_D <= 3                  lift=    1.65  pos=85.23%  neg=51.58%\n",
            "    Total_Points <= 14         lift=    1.54  pos=46.86%  neg=30.34%\n"
          ]
        }
      ],
      "source": [
        "# Inspect criteria_with_metrics for sample auctions\n",
        "print(\"Inspecting criteria_with_metrics for selected auctions:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for auc in SAMPLE_AUCTIONS:\n",
        "    row = df.filter(pl.col(\"step_auction\") == auc).to_dicts()\n",
        "    if row:\n",
        "        row = row[0]\n",
        "        print(f\"\\n{auc} (seat {row['seat']}, {row['pos_count']:,} deals):\")\n",
        "        print(f\"  Base rules: {row['base_rules']}\")\n",
        "        print(f\"  Discovered criteria with metrics:\")\n",
        "        for m in row[\"criteria_with_metrics\"]:\n",
        "            lift_str = f\"{m['lift']:.2f}\" if m['lift'] is not None else \"inf\"\n",
        "            print(f\"    {m['criterion']:25s}  lift={lift_str:>8s}  pos={m['pos_rate']:>6.2%}  neg={m['neg_rate']:>6.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Threshold-Based Filtering\n",
        "\n",
        "Filter criteria based on configured thresholds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_criteria(\n",
        "    criteria_with_metrics: List[Dict],\n",
        "    pos_count: int,\n",
        "    min_lift: float = MIN_LIFT,\n",
        "    min_pos_rate: float = MIN_POS_RATE,\n",
        "    min_pos_count: int = MIN_POS_COUNT,\n",
        "    max_neg_rate: float = MAX_NEG_RATE,\n",
        "    high_confidence_pos_rate: float = HIGH_CONFIDENCE_POS_RATE,\n",
        ") -> Tuple[List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Filter criteria based on thresholds, preferring most restrictive high-confidence bounds.\n",
        "    \n",
        "    Args:\n",
        "        criteria_with_metrics: List of dicts with 'criterion', 'lift', 'pos_rate', 'neg_rate'\n",
        "        pos_count: Total positive count for the group (used to compute absolute criterion count)\n",
        "        min_lift: Minimum lift threshold\n",
        "        min_pos_rate: Minimum positive rate threshold\n",
        "        min_pos_count: Minimum absolute positive count threshold\n",
        "        max_neg_rate: Maximum negative rate threshold\n",
        "        high_confidence_pos_rate: Threshold for preferring most restrictive bound (default 98%)\n",
        "    \n",
        "    Returns:\n",
        "        (accepted_criteria, rejected_criteria)\n",
        "        \n",
        "    The function implements a two-phase acceptance strategy:\n",
        "    1. First pass: accept all criteria that pass basic thresholds (lift, pos_rate >= 50%, etc.)\n",
        "    2. Second pass: for each (variable, operator) group with multiple accepted criteria,\n",
        "       select the MOST RESTRICTIVE one that still passes high_confidence_pos_rate (98%):\n",
        "       - For >= (lower bounds): most restrictive = HIGHEST value\n",
        "       - For <= (upper bounds): most restrictive = LOWEST value\n",
        "       \n",
        "    This prevents less restrictive but technically true criteria (like SL_H >= 4) from\n",
        "    overshadowing the actual convention requirements (like SL_H >= 5).\n",
        "    \"\"\"\n",
        "    if not criteria_with_metrics:\n",
        "        return [], []\n",
        "    \n",
        "    # Phase 1: Determine which criteria pass basic thresholds\n",
        "    # Keep track of both criterion string AND its pos_rate for phase 2\n",
        "    passed_basic: List[Tuple[str, float]] = []  # (criterion, pos_rate)\n",
        "    rejected = []\n",
        "    \n",
        "    for m in criteria_with_metrics:\n",
        "        criterion = m[\"criterion\"]\n",
        "        lift = m.get(\"lift\")  # None means infinity\n",
        "        pos_rate = m.get(\"pos_rate\", 0)\n",
        "        neg_rate = m.get(\"neg_rate\", 0)\n",
        "        \n",
        "        # Calculate absolute positive count for this criterion\n",
        "        crit_pos_count = int(pos_rate * pos_count)\n",
        "        \n",
        "        # Check all conditions\n",
        "        lift_ok = (lift is None) or (lift >= min_lift)\n",
        "        pos_rate_ok = pos_rate >= min_pos_rate\n",
        "        pos_count_ok = crit_pos_count >= min_pos_count\n",
        "        neg_rate_ok = neg_rate <= max_neg_rate\n",
        "        \n",
        "        if lift_ok and pos_rate_ok and pos_count_ok and neg_rate_ok:\n",
        "            passed_basic.append((criterion, pos_rate))\n",
        "        else:\n",
        "            rejected.append(criterion)\n",
        "    \n",
        "    if not passed_basic:\n",
        "        return [], rejected\n",
        "    \n",
        "    # Phase 2: For each (variable, operator) group, select the most restrictive\n",
        "    # bound that still passes the high-confidence threshold\n",
        "    #\n",
        "    # Logic:\n",
        "    # - For >= (lower bounds): higher value is more restrictive\n",
        "    #   E.g., SL_H >= 5 is more restrictive than SL_H >= 4\n",
        "    # - For <= (upper bounds): lower value is more restrictive\n",
        "    #   E.g., SL_S <= 3 is more restrictive than SL_S <= 5\n",
        "    \n",
        "    # Group numeric criteria by (variable, operator)\n",
        "    # Key: (var_name, op) -> List of (value, pos_rate)\n",
        "    numeric_groups: Dict[Tuple[str, str], List[Tuple[int, float]]] = {}\n",
        "    non_numeric: List[str] = []\n",
        "    \n",
        "    for criterion, pos_rate in passed_basic:\n",
        "        parsed = _parse_ineq_for_filter(criterion)\n",
        "        if parsed:\n",
        "            var_name, op, value = parsed\n",
        "            key = (var_name, op)\n",
        "            if key not in numeric_groups:\n",
        "                numeric_groups[key] = []\n",
        "            numeric_groups[key].append((value, pos_rate))\n",
        "        else:\n",
        "            # Non-numeric criterion - keep as-is\n",
        "            non_numeric.append(criterion)\n",
        "    \n",
        "    # Select best bound for each group\n",
        "    accepted = []\n",
        "    \n",
        "    for (var_name, op), candidates in numeric_groups.items():\n",
        "        # Filter to high-confidence candidates\n",
        "        high_conf = [(v, pr) for v, pr in candidates if pr >= high_confidence_pos_rate]\n",
        "        \n",
        "        if high_conf:\n",
        "            # Select most restrictive among high-confidence candidates\n",
        "            if op in ('>=', '>'):\n",
        "                # Higher value is more restrictive for lower bounds\n",
        "                best_value = max(v for v, _ in high_conf)\n",
        "            else:  # <=, <\n",
        "                # Lower value is more restrictive for upper bounds\n",
        "                best_value = min(v for v, _ in high_conf)\n",
        "            accepted.append(f\"{var_name} {op} {best_value}\")\n",
        "        else:\n",
        "            # No high-confidence candidate - fall back to least restrictive\n",
        "            # (original behavior for low-confidence scenarios)\n",
        "            if op in ('>=', '>'):\n",
        "                best_value = min(v for v, _ in candidates)\n",
        "            else:\n",
        "                best_value = max(v for v, _ in candidates)\n",
        "            accepted.append(f\"{var_name} {op} {best_value}\")\n",
        "    \n",
        "    # Add non-numeric criteria\n",
        "    accepted.extend(non_numeric)\n",
        "    \n",
        "    return accepted, rejected\n",
        "\n",
        "\n",
        "def _parse_ineq_for_filter(expr: str):\n",
        "    \"\"\"Parse inequality expression for filter_criteria. Returns (var_name, op, value) or None.\"\"\"\n",
        "    m = INEQUALITY_RE.match(expr.strip())\n",
        "    if not m:\n",
        "        return None\n",
        "    name, op, value_str = m.groups()\n",
        "    try:\n",
        "        v = int(value_str)\n",
        "    except ValueError:\n",
        "        return None\n",
        "    return name, op, v\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merge / Deduplicate Numeric Criteria (Safe)\n",
        "\n",
        "We observed that learned criteria can sometimes produce **contradictory** numeric bounds versus the BT base criteria\n",
        "(e.g., `HCP <= 7` for `1S-p-p-p`).\n",
        "\n",
        "In this notebook we treat `bt_seat1_df.Agg_Expr_Seat_1` as the **canonical base** constraints, then merge in\n",
        "accepted learned criteria *additively*.\n",
        "\n",
        "For numeric inequalities (e.g. `HCP`, `Total_Points`, `SL_S`):\n",
        "- BT base numeric bounds are **canonical** (we do **not** tighten them with learned criteria)\n",
        "- Accepted numeric bounds are only used when BT has **no numeric bound at all** for that metric\n",
        "- When we do use accepted numeric bounds, we keep the **least restrictive** bound among accepted criteria\n",
        "  (lower bounds: smallest value; upper bounds: largest value)\n",
        "\n",
        "Relative comparisons (e.g. `SL_S >= SL_H`) are preserved as additional constraints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge / dedupe helpers\n",
        "# \n",
        "# Key changes vs the previous implementation:\n",
        "# - We treat BT seat-1 criteria as the canonical base (joined in Cell 2).\n",
        "# - We merge ACCEPTED criteria *additively*.\n",
        "# - For numeric inequalities (HCP / Total_Points / SL_*), we keep the tightest consistent bounds:\n",
        "#     lower bound  -> max\n",
        "#     upper bound  -> min\n",
        "#   and we DROP any accepted bound that contradicts the base interval.\n",
        "# \n",
        "# This prevents pathological learned constraints like HCP <= 7 for 1S openings.\n",
        "\n",
        "def _parse_ineq(expr: str):\n",
        "    m = INEQUALITY_RE.match(expr.strip())\n",
        "    if not m:\n",
        "        return None\n",
        "    name, op, value = m.groups()\n",
        "    try:\n",
        "        v = int(value)\n",
        "    except Exception:\n",
        "        return None\n",
        "    return name, op, v\n",
        "\n",
        "\n",
        "def _bounds_from(criteria: List[str]) -> Tuple[Dict[str, int], Dict[str, int]]:\n",
        "    lo: Dict[str, int] = {}\n",
        "    hi: Dict[str, int] = {}\n",
        "    for c in criteria or []:\n",
        "        p = _parse_ineq(c)\n",
        "        if not p:\n",
        "            continue\n",
        "        name, op, v = p\n",
        "        if op in (\">=\", \">\"):\n",
        "            lo[name] = max(lo.get(name, v), v)\n",
        "        elif op in (\"<=\", \"<\"):\n",
        "            hi[name] = min(hi.get(name, v), v)\n",
        "        elif op == \"==\":\n",
        "            lo[name] = max(lo.get(name, v), v)\n",
        "            hi[name] = min(hi.get(name, v), v)\n",
        "    return lo, hi\n",
        "\n",
        "\n",
        "def dedupe_criteria_least_restrictive(criteria: List[str]) -> List[str]:\n",
        "    \"\"\"Deduplicate criteria list, keeping least restrictive bounds for each variable.\n",
        "    \n",
        "    When multiple criteria refer to the same variable with the same operator:\n",
        "    - For >= or >: keep the SMALLEST value (allows more hands through)\n",
        "    - For <= or <: keep the LARGEST value (allows more hands through)\n",
        "    \n",
        "    Examples:\n",
        "        [\"HCP >= 3\", \"HCP >= 5\", \"HCP <= 10\"]  -> [\"HCP >= 3\", \"HCP <= 10\"]\n",
        "        [\"SL_S >= 4\", \"SL_S >= 2\", \"Balanced\"] -> [\"SL_S >= 2\", \"Balanced\"]\n",
        "    \"\"\"\n",
        "    if not criteria:\n",
        "        return []\n",
        "    \n",
        "    # Track inequalities: (var_name, operator) -> best_value\n",
        "    inequalities: Dict[Tuple[str, str], int] = {}\n",
        "    # Track non-numeric criteria (preserve order)\n",
        "    other: List[str] = []\n",
        "    \n",
        "    for crit in criteria:\n",
        "        crit_str = str(crit).strip()\n",
        "        p = _parse_ineq(crit_str)\n",
        "        if p:\n",
        "            name, op, v = p\n",
        "            key = (name, op)\n",
        "            if key not in inequalities:\n",
        "                inequalities[key] = v\n",
        "            else:\n",
        "                existing = inequalities[key]\n",
        "                # For lower bounds (>=, >): keep smallest (least restrictive)\n",
        "                if op in ('>=', '>'):\n",
        "                    if v < existing:\n",
        "                        inequalities[key] = v\n",
        "                # For upper bounds (<=, <): keep largest (least restrictive)\n",
        "                elif op in ('<=', '<'):\n",
        "                    if v > existing:\n",
        "                        inequalities[key] = v\n",
        "                # For ==: first wins\n",
        "        else:\n",
        "            # Non-numeric criterion - add if not already present\n",
        "            if crit_str not in other:\n",
        "                other.append(crit_str)\n",
        "    \n",
        "    # Combine: inequalities first (sorted for consistency), then other\n",
        "    result = [f\"{name} {op} {v}\" for (name, op), v in sorted(inequalities.items())]\n",
        "    result.extend(other)\n",
        "    return result\n",
        "\n",
        "\n",
        "def merge_rules(base_rules: List[str], accepted_criteria: List[str]) -> List[str]:\n",
        "    \"\"\"Merge BT base_rules with accepted_criteria.\n",
        "\n",
        "    UPDATED POLICY (for correctness + Arena matching):\n",
        "    - BT numeric inequalities are canonical. If BT already constrains a numeric metric\n",
        "      (HCP / Total_Points / SL_*), we do **not** tighten it with learned criteria.\n",
        "      This prevents pathological tightening like adding `Total_Points <= 6` on top of\n",
        "      a BT base `Total_Points <= 18`.\n",
        "    - For numeric metrics that BT does *not* constrain at all, we may add learned bounds,\n",
        "      but we keep the **least restrictive** bound among accepted criteria:\n",
        "        - lower bounds (>=, >): keep the smallest value\n",
        "        - upper bounds (<=, <): keep the largest value\n",
        "    - Non-numeric accepted criteria (including relative SL comparisons) are appended.\n",
        "    \"\"\"\n",
        "    base = [str(x).strip() for x in (base_rules or []) if str(x).strip()]\n",
        "    accepted = [str(x).strip() for x in (accepted_criteria or []) if str(x).strip()]\n",
        "    if not accepted:\n",
        "        return base\n",
        "\n",
        "    base_lo, base_hi = _bounds_from(base)\n",
        "    base_constrained = set(base_lo.keys()) | set(base_hi.keys())\n",
        "\n",
        "    kept_other: List[str] = []\n",
        "    kept_eq_ne: List[str] = []\n",
        "    add_lo: Dict[str, int] = {}\n",
        "    add_hi: Dict[str, int] = {}\n",
        "\n",
        "    for c in accepted:\n",
        "        cs = str(c).strip()\n",
        "        p = _parse_ineq(cs)\n",
        "        if not p:\n",
        "            kept_other.append(cs)\n",
        "            continue\n",
        "\n",
        "        name, op, v = p\n",
        "\n",
        "        # Equality/inequality operators: keep verbatim\n",
        "        if op in (\"==\", \"!=\"):\n",
        "            kept_eq_ne.append(cs)\n",
        "            continue\n",
        "\n",
        "        # Only treat these as numeric metrics; everything else is \"other\"\n",
        "        if name not in (\"HCP\", \"Total_Points\") and not name.startswith(\"SL_\"):\n",
        "            kept_other.append(cs)\n",
        "            continue\n",
        "\n",
        "        # If BT already constrains this metric, do not add/tighten it\n",
        "        if name in base_constrained:\n",
        "            continue\n",
        "\n",
        "        if op in (\">=\", \">\"):\n",
        "            add_lo[name] = min(add_lo.get(name, v), v)\n",
        "        elif op in (\"<=\", \"<\"):\n",
        "            add_hi[name] = max(add_hi.get(name, v), v)\n",
        "\n",
        "    out: List[str] = []\n",
        "    out.extend(base)\n",
        "\n",
        "    for name in sorted(add_lo.keys()):\n",
        "        out.append(f\"{name} >= {add_lo[name]}\")\n",
        "    for name in sorted(add_hi.keys()):\n",
        "        out.append(f\"{name} <= {add_hi[name]}\")\n",
        "\n",
        "    # Add non-numeric criteria and eq/ne criteria (dedup preserving order)\n",
        "    seen = set(out)\n",
        "    for c in kept_other + kept_eq_ne:\n",
        "        if c and c not in seen:\n",
        "            out.append(c)\n",
        "            seen.add(c)\n",
        "\n",
        "    # Final deduplication: keep least restrictive bounds for each variable\n",
        "    return dedupe_criteria_least_restrictive(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test filter_criteria on '1n':\n",
            "  Accepted: ['HCP >= 14', 'Total_Points >= 15']\n",
            "  Rejected: []\n",
            "\n",
            "Test merge_rules (BT numeric bounds canonical):\n",
            "  Base rules: ['HCP >= 12', 'HCP <= 21', 'Total_Points >= 12', 'Total_Points <= 22', 'SL_S >= 5']\n",
            "  Accepted:   ['HCP <= 7', 'HCP >= 13', 'SL_S >= SL_H']\n",
            "  Merged:     ['HCP <= 21', 'HCP >= 12', 'SL_S >= 5', 'Total_Points <= 22', 'Total_Points >= 12', 'SL_S >= SL_H']\n"
          ]
        }
      ],
      "source": [
        "# Sanity tests (executable)\n",
        "# Test filter_criteria\n",
        "sample_row = df.filter(pl.col(\"step_auction\") == \"1n\").to_dicts()[0]\n",
        "acc, rej = filter_criteria(\n",
        "    sample_row[\"criteria_with_metrics\"],\n",
        "    sample_row[\"pos_count\"],\n",
        ")\n",
        "print(\"Test filter_criteria on '1n':\")\n",
        "print(f\"  Accepted: {acc}\")\n",
        "print(f\"  Rejected: {rej}\")\n",
        "print()\n",
        "\n",
        "# Test merge_rules (do not tighten BT numeric bounds)\n",
        "test_base = [\"HCP >= 12\", \"HCP <= 21\", \"Total_Points >= 12\", \"Total_Points <= 22\", \"SL_S >= 5\"]\n",
        "# accepted contains a contradiction (HCP <= 7) and a tightening (HCP >= 13), but BT already constrains HCP,\n",
        "# so numeric HCP bounds should NOT be tightened. Relative criteria should still be preserved.\n",
        "test_accepted = [\"HCP <= 7\", \"HCP >= 13\", \"SL_S >= SL_H\"]\n",
        "print(\"Test merge_rules (BT numeric bounds canonical):\")\n",
        "print(f\"  Base rules: {test_base}\")\n",
        "print(f\"  Accepted:   {test_accepted}\")\n",
        "print(f\"  Merged:     {merge_rules(test_base, test_accepted)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply to All Rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing all rows...\n",
            "  Processed 66,814 rows\n",
            "  New columns: Accepted_Criteria, Rejected_Criteria, Merged_Rules\n"
          ]
        }
      ],
      "source": [
        "# Process all rows\n",
        "print(\"Processing all rows...\")\n",
        "\n",
        "# Convert to list of dicts for processing\n",
        "rows = df.to_dicts()\n",
        "\n",
        "accepted_list = []\n",
        "rejected_list = []\n",
        "merged_list = []\n",
        "\n",
        "for row in rows:\n",
        "    # Filter criteria based on thresholds\n",
        "    accepted, rejected = filter_criteria(\n",
        "        row.get(\"criteria_with_metrics\", []),\n",
        "        row.get(\"pos_count\", 0),\n",
        "    )\n",
        "    \n",
        "    # Merge base_rules with accepted criteria (with deduplication)\n",
        "    merged = merge_rules(\n",
        "        row.get(\"base_rules\", []),\n",
        "        accepted\n",
        "    )\n",
        "    \n",
        "    accepted_list.append(accepted)\n",
        "    rejected_list.append(rejected)\n",
        "    merged_list.append(merged)\n",
        "\n",
        "# Add new columns\n",
        "result_df = df.with_columns([\n",
        "    pl.Series(\"Accepted_Criteria\", accepted_list),\n",
        "    pl.Series(\"Rejected_Criteria\", rejected_list),\n",
        "    pl.Series(\"Merged_Rules\", merged_list),\n",
        "])\n",
        "\n",
        "print(f\"  Processed {result_df.height:,} rows\")\n",
        "print(f\"  New columns: Accepted_Criteria, Rejected_Criteria, Merged_Rules\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preview of results:\n",
            "shape: (20, 6)\n",
            "┌──────────────┬───────────┬─────────────────┬─────────────────┬─────────────────┬─────────────────┐\n",
            "│ step_auction ┆ pos_count ┆ base_rules      ┆ Accepted_Criter ┆ Rejected_Criter ┆ Merged_Rules    │\n",
            "│ ---          ┆ ---       ┆ ---             ┆ ia              ┆ ia              ┆ ---             │\n",
            "│ str          ┆ i64       ┆ list[str]       ┆ ---             ┆ ---             ┆ list[str]       │\n",
            "│              ┆           ┆                 ┆ list[str]       ┆ list[str]       ┆                 │\n",
            "╞══════════════╪═══════════╪═════════════════╪═════════════════╪═════════════════╪═════════════════╡\n",
            "│ 1d           ┆ 3507593   ┆ [\"HCP <= 21\",   ┆ [\"SL_D >= 3\"]   ┆ [\"SL_D >= 6\",   ┆ [\"HCP <= 21\",   │\n",
            "│              ┆           ┆ \"HCP >= 11\", …  ┆                 ┆ \"SL_S <= 1\",    ┆ \"HCP >= 11\", …  │\n",
            "│              ┆           ┆ \"…              ┆                 ┆ \"SL…            ┆ \"…              │\n",
            "│ 1c           ┆ 3446023   ┆ [\"HCP <= 21\",   ┆ [\"SL_C >= 3\",   ┆ [\"SL_C >= 6\",   ┆ [\"HCP <= 21\",   │\n",
            "│              ┆           ┆ \"HCP >= 11\", …  ┆ \"SL_D <= 3\"]    ┆ \"Total_Points   ┆ \"HCP >= 11\", …  │\n",
            "│              ┆           ┆ \"…              ┆                 ┆ <=…             ┆ \"…              │\n",
            "│ 1n           ┆ 2518162   ┆ [\"HCP <= 17\",   ┆ [\"HCP >= 14\",   ┆ []              ┆ [\"HCP <= 17\",   │\n",
            "│              ┆           ┆ \"HCP >= 15\", …  ┆ \"Total_Points   ┆                 ┆ \"HCP >= 15\", …  │\n",
            "│              ┆           ┆ \"…              ┆ >=…             ┆                 ┆ \"…              │\n",
            "│ 1s           ┆ 2497723   ┆ [\"HCP <= 21\",   ┆ [\"SL_S >= 5\"]   ┆ [\"SL_S >= 6\",   ┆ [\"HCP <= 21\",   │\n",
            "│              ┆           ┆ \"HCP >= 11\", …  ┆                 ┆ \"SL_H <= 1\", …  ┆ \"HCP >= 11\", …  │\n",
            "│              ┆           ┆ \"…              ┆                 ┆ \"…              ┆ \"…              │\n",
            "│ 1h           ┆ 2363106   ┆ [\"HCP <= 21\",   ┆ [\"SL_H >= 5\"]   ┆ [\"SL_H >= 6\",   ┆ [\"HCP <= 21\",   │\n",
            "│              ┆           ┆ \"HCP >= 11\", …  ┆                 ┆ \"SL_S <= 1\", …  ┆ \"HCP >= 11\", …  │\n",
            "│              ┆           ┆ \"…              ┆                 ┆ \"…              ┆ \"…              │\n",
            "│ …            ┆ …         ┆ …               ┆ …               ┆ …               ┆ …               │\n",
            "│ 1d-p-1h-p    ┆ 607804    ┆ [\"Total_Points  ┆ []              ┆ [\"Total_Points  ┆ [\"Total_Points  │\n",
            "│              ┆           ┆ <= 20\"]         ┆                 ┆ <= 6\",          ┆ <= 20\"]         │\n",
            "│              ┆           ┆                 ┆                 ┆ \"Total_P…       ┆                 │\n",
            "│ 1c-p-1s      ┆ 590588    ┆ [\"SL_S >= 4\",   ┆ [\"SL_S >= 4\",   ┆ [\"SL_S >= 6\",   ┆ [\"SL_H <= 3\",   │\n",
            "│              ┆           ┆ \"Total_Points   ┆ \"SL_H <= 3\"]    ┆ \"SL_H <= 1\",    ┆ \"SL_S >= 4\",    │\n",
            "│              ┆           ┆ >=…             ┆                 ┆ \"SL…            ┆ \"To…            │\n",
            "│ 1n-p-2c      ┆ 590415    ┆ []              ┆ [\"HCP >= 8\",    ┆ [\"HCP >= 11\"]   ┆ [\"HCP >= 8\",    │\n",
            "│              ┆           ┆                 ┆ \"Total_Points   ┆                 ┆ \"Total_Points   │\n",
            "│              ┆           ┆                 ┆ >= …            ┆                 ┆ >= …            │\n",
            "│ 1n-p-2c-p    ┆ 567114    ┆ [\"Total_Points  ┆ [\"Total_Points  ┆ [\"Total_Points  ┆ [\"Total_Points  │\n",
            "│              ┆           ┆ <= 20\"]         ┆ <= 8\"]          ┆ <= 5\",          ┆ <= 20\"]         │\n",
            "│              ┆           ┆                 ┆                 ┆ \"Total_P…       ┆                 │\n",
            "│ 1n-p-p       ┆ 560160    ┆ [\"HCP <= 8\",    ┆ [\"Total_Points  ┆ [\"Total_Points  ┆ [\"HCP <= 8\",    │\n",
            "│              ┆           ┆ \"Total_Points   ┆ <= 8\"]          ┆ <= 4\",          ┆ \"Total_Points   │\n",
            "│              ┆           ┆ <= …            ┆                 ┆ \"Total_P…       ┆ <= …            │\n",
            "└──────────────┴───────────┴─────────────────┴─────────────────┴─────────────────┴─────────────────┘\n"
          ]
        }
      ],
      "source": [
        "# Preview results\n",
        "print(\"Preview of results:\")\n",
        "display_cols = [\"step_auction\", \"pos_count\", \"base_rules\", \"Accepted_Criteria\", \"Rejected_Criteria\", \"Merged_Rules\"]\n",
        "print(result_df.select([c for c in display_cols if c in result_df.columns]).head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detailed inspection of sample auctions:\n",
            "====================================================================================================\n",
            "\n",
            "1n (seat 1, 2,518,162 pos, 13,476,665 neg):\n",
            "  Base rules:        ['HCP <= 17', 'HCP >= 15', 'SL_C <= 5', 'SL_C >= 2', 'SL_D <= 5', 'SL_D >= 2', 'SL_H <= 5', 'SL_H >= 2', 'SL_S <= 5', 'SL_S >= 2', 'Total_Points <= 18']\n",
            "  Accepted criteria: ['HCP >= 14', 'Total_Points >= 15']\n",
            "  Rejected criteria: []\n",
            "  Merged rules:      ['HCP <= 17', 'HCP >= 15', 'SL_C <= 5', 'SL_C >= 2', 'SL_D <= 5', 'SL_D >= 2', 'SL_H <= 5', 'SL_H >= 2', 'SL_S <= 5', 'SL_S >= 2', 'Total_Points <= 18']\n",
            "  Criteria details:\n",
            "    ✗ HCP >= 15                  lift=    2.64  pos=87.78%  neg=33.23%\n",
            "    ✗ HCP >= 16                  lift=    2.17  pos=54.79%  neg=25.29%\n",
            "    ✓ HCP >= 14                  lift=    2.00  pos=96.92%  neg=48.43%\n",
            "    ✗ Total_Points >= 16         lift=    1.85  pos=83.28%  neg=45.13%\n",
            "    ✓ Total_Points >= 15         lift=    1.59  pos=96.38%  neg=60.44%\n",
            "    ✗ Total_Points >= 17         lift=    1.54  pos=53.85%  neg=34.93%\n",
            "\n",
            "1s (seat 1, 2,497,723 pos, 13,497,104 neg):\n",
            "  Base rules:        ['HCP <= 21', 'HCP >= 11', 'SL_S >= 5', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Accepted criteria: ['SL_S >= 5']\n",
            "  Rejected criteria: ['SL_S >= 6', 'SL_H <= 1', 'SL_D <= 1', 'SL_C <= 1']\n",
            "  Merged rules:      ['HCP <= 21', 'HCP >= 11', 'SL_S >= 5', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Criteria details:\n",
            "    ✓ SL_S >= 5                  lift=   22.26  pos=99.32%  neg= 4.46%\n",
            "    ✗ SL_S >= 6                  lift=   13.55  pos=32.57%  neg= 2.40%\n",
            "    ✗ SL_S >= 4                  lift=    3.23  pos=99.93%  neg=30.91%\n",
            "    ✗ SL_H <= 1                  lift=    2.50  pos=20.62%  neg= 8.26%\n",
            "    ✗ SL_D <= 1                  lift=    2.40  pos=20.15%  neg= 8.41%\n",
            "    ✗ SL_C <= 1                  lift=    2.35  pos=20.44%  neg= 8.71%\n",
            "\n",
            "1h (seat 1, 2,363,106 pos, 13,631,721 neg):\n",
            "  Base rules:        ['HCP <= 21', 'HCP >= 11', 'SL_H >= 5', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Accepted criteria: ['SL_H >= 5']\n",
            "  Rejected criteria: ['SL_H >= 6', 'SL_S <= 1', 'SL_D <= 1', 'SL_C <= 1']\n",
            "  Merged rules:      ['HCP <= 21', 'HCP >= 11', 'SL_H >= 5', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Criteria details:\n",
            "    ✓ SL_H >= 5                  lift=   18.68  pos=99.16%  neg= 5.31%\n",
            "    ✗ SL_H >= 6                  lift=   13.89  pos=33.74%  neg= 2.43%\n",
            "    ✗ SL_H >= 4                  lift=    3.21  pos=99.92%  neg=31.17%\n",
            "    ✗ SL_S <= 1                  lift=    2.69  pos=21.59%  neg= 8.03%\n",
            "    ✗ SL_D <= 1                  lift=    2.17  pos=18.93%  neg= 8.74%\n",
            "    ✗ SL_C <= 1                  lift=    2.14  pos=19.33%  neg= 9.02%\n",
            "\n",
            "1d (seat 1, 3,507,593 pos, 12,487,234 neg):\n",
            "  Base rules:        ['HCP <= 21', 'HCP >= 11', 'SL_D >= 3', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Accepted criteria: ['SL_D >= 3']\n",
            "  Rejected criteria: ['SL_D >= 6', 'SL_S <= 1', 'SL_H <= 1']\n",
            "  Merged rules:      ['HCP <= 21', 'HCP >= 11', 'SL_D >= 3', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Criteria details:\n",
            "    ✗ SL_D >= 6                  lift=    8.14  pos=21.21%  neg= 2.61%\n",
            "    ✗ SL_D >= 5                  lift=    6.98  pos=56.52%  neg= 8.09%\n",
            "    ✗ SL_D >= 4                  lift=    3.58  pos=94.14%  neg=26.29%\n",
            "    ✓ SL_D >= 3                  lift=    1.64  pos=99.35%  neg=60.42%\n",
            "    ✗ SL_S <= 1                  lift=    1.61  pos=14.28%  neg= 8.84%\n",
            "    ✗ SL_H <= 1                  lift=    1.59  pos=14.37%  neg= 9.02%\n",
            "\n",
            "1c (seat 1, 3,446,023 pos, 12,548,804 neg):\n",
            "  Base rules:        ['HCP <= 21', 'HCP >= 11', 'SL_C >= 3', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Accepted criteria: ['SL_C >= 3', 'SL_D <= 3']\n",
            "  Rejected criteria: ['SL_C >= 6', 'Total_Points <= 14']\n",
            "  Merged rules:      ['HCP <= 21', 'HCP >= 11', 'SL_C >= 3', 'SL_D <= 3', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Criteria details:\n",
            "    ✗ SL_C >= 6                  lift=   15.38  pos=21.05%  neg= 1.37%\n",
            "    ✗ SL_C >= 5                  lift=    6.86  pos=52.26%  neg= 7.62%\n",
            "    ✗ SL_C >= 4                  lift=    2.89  pos=81.81%  neg=28.32%\n",
            "    ✓ SL_C >= 3                  lift=    1.65  pos=98.60%  neg=59.67%\n",
            "    ✓ SL_D <= 3                  lift=    1.65  pos=85.23%  neg=51.58%\n",
            "    ✗ Total_Points <= 14         lift=    1.54  pos=46.86%  neg=30.34%\n"
          ]
        }
      ],
      "source": [
        "# Detailed inspection of sample auctions\n",
        "print(\"Detailed inspection of sample auctions:\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "for auc in SAMPLE_AUCTIONS:\n",
        "    rows = result_df.filter(pl.col(\"step_auction\") == auc).to_dicts()\n",
        "    if rows:\n",
        "        row = rows[0]\n",
        "        print(f\"\\n{auc} (seat {row['seat']}, {row['pos_count']:,} pos, {row['neg_count']:,} neg):\")\n",
        "        print(f\"  Base rules:        {row['base_rules']}\")\n",
        "        print(f\"  Accepted criteria: {row['Accepted_Criteria']}\")\n",
        "        print(f\"  Rejected criteria: {row['Rejected_Criteria']}\")\n",
        "        print(f\"  Merged rules:      {row['Merged_Rules']}\")\n",
        "        \n",
        "        # Show criteria with metrics\n",
        "        print(f\"  Criteria details:\")\n",
        "        for m in row.get(\"criteria_with_metrics\", []):\n",
        "            lift_str = f\"{m['lift']:.2f}\" if m['lift'] is not None else \"inf\"\n",
        "            status = \"✓\" if m['criterion'] in row['Accepted_Criteria'] else \"✗\"\n",
        "            print(f\"    {status} {m['criterion']:25s}  lift={lift_str:>8s}  pos={m['pos_rate']:>6.2%}  neg={m['neg_rate']:>6.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acceptance Statistics:\n",
            "============================================================\n",
            "\n",
            "Rows with at least 1 accepted criterion: 60,351\n",
            "Rows with no accepted criteria: 6,463\n",
            "\n",
            "Distribution of accepted criteria count:\n",
            "shape: (7, 2)\n",
            "┌────────────┬───────┐\n",
            "│ n_accepted ┆ count │\n",
            "│ ---        ┆ ---   │\n",
            "│ u64        ┆ u64   │\n",
            "╞════════════╪═══════╡\n",
            "│ 0          ┆ 6463  │\n",
            "│ 1          ┆ 15543 │\n",
            "│ 2          ┆ 30103 │\n",
            "│ 3          ┆ 10710 │\n",
            "│ 4          ┆ 3437  │\n",
            "│ 5          ┆ 522   │\n",
            "│ 6          ┆ 36    │\n",
            "└────────────┴───────┘\n",
            "\n",
            "Distribution of rejected criteria count:\n",
            "shape: (7, 2)\n",
            "┌────────────┬───────┐\n",
            "│ n_rejected ┆ count │\n",
            "│ ---        ┆ ---   │\n",
            "│ u64        ┆ u64   │\n",
            "╞════════════╪═══════╡\n",
            "│ 0          ┆ 8581  │\n",
            "│ 1          ┆ 4083  │\n",
            "│ 2          ┆ 9347  │\n",
            "│ 3          ┆ 13718 │\n",
            "│ 4          ┆ 15072 │\n",
            "│ 5          ┆ 10976 │\n",
            "│ 6          ┆ 5037  │\n",
            "└────────────┴───────┘\n"
          ]
        }
      ],
      "source": [
        "# Acceptance statistics\n",
        "print(\"Acceptance Statistics:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Count accepted/rejected per row\n",
        "stats_df = result_df.with_columns([\n",
        "    pl.col(\"Accepted_Criteria\").list.len().alias(\"n_accepted\"),\n",
        "    pl.col(\"Rejected_Criteria\").list.len().alias(\"n_rejected\"),\n",
        "    pl.col(\"Merged_Rules\").list.len().alias(\"n_merged\"),\n",
        "    pl.col(\"base_rules\").list.len().alias(\"n_base\"),\n",
        "    pl.col(\"discovered_rules\").list.len().alias(\"n_discovered\"),\n",
        "])\n",
        "\n",
        "print(f\"\\nRows with at least 1 accepted criterion: {stats_df.filter(pl.col('n_accepted') > 0).height:,}\")\n",
        "print(f\"Rows with no accepted criteria: {stats_df.filter(pl.col('n_accepted') == 0).height:,}\")\n",
        "\n",
        "print(\"\\nDistribution of accepted criteria count:\")\n",
        "print(stats_df.group_by(\"n_accepted\").agg(pl.len().alias(\"count\")).sort(\"n_accepted\"))\n",
        "\n",
        "print(\"\\nDistribution of rejected criteria count:\")\n",
        "print(stats_df.group_by(\"n_rejected\").agg(pl.len().alias(\"count\")).sort(\"n_rejected\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 20 most commonly accepted criteria:\n",
            "shape: (20, 2)\n",
            "┌────────────────────┬───────┐\n",
            "│ criterion          ┆ count │\n",
            "│ ---                ┆ ---   │\n",
            "│ str                ┆ u64   │\n",
            "╞════════════════════╪═══════╡\n",
            "│ Total_Points <= 14 ┆ 4030  │\n",
            "│ Total_Points <= 15 ┆ 3837  │\n",
            "│ HCP <= 12          ┆ 3509  │\n",
            "│ HCP <= 13          ┆ 3195  │\n",
            "│ Total_Points <= 13 ┆ 3164  │\n",
            "│ …                  ┆ …     │\n",
            "│ SL_H >= 4          ┆ 1977  │\n",
            "│ SL_C >= 3          ┆ 1951  │\n",
            "│ SL_D >= 4          ┆ 1945  │\n",
            "│ Total_Points <= 9  ┆ 1942  │\n",
            "│ SL_S <= 2          ┆ 1941  │\n",
            "└────────────────────┴───────┘\n"
          ]
        }
      ],
      "source": [
        "# Most commonly accepted criteria\n",
        "print(\"\\nTop 20 most commonly accepted criteria:\")\n",
        "all_accepted = result_df.select(pl.col(\"Accepted_Criteria\").explode().alias(\"criterion\")).drop_nulls()\n",
        "accepted_counts = all_accepted.group_by(\"criterion\").agg(pl.len().alias(\"count\")).sort(\"count\", descending=True)\n",
        "print(accepted_counts.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 20 most commonly rejected criteria:\n",
            "shape: (20, 2)\n",
            "┌────────────────────┬───────┐\n",
            "│ criterion          ┆ count │\n",
            "│ ---                ┆ ---   │\n",
            "│ str                ┆ u64   │\n",
            "╞════════════════════╪═══════╡\n",
            "│ Total_Points <= 13 ┆ 6939  │\n",
            "│ HCP <= 11          ┆ 5248  │\n",
            "│ SL_C <= 1          ┆ 4534  │\n",
            "│ SL_D <= 1          ┆ 4391  │\n",
            "│ HCP <= 12          ┆ 4205  │\n",
            "│ …                  ┆ …     │\n",
            "│ Total_Points >= 18 ┆ 3070  │\n",
            "│ HCP <= 5           ┆ 3053  │\n",
            "│ Total_Points <= 10 ┆ 3045  │\n",
            "│ SL_C >= 4          ┆ 3037  │\n",
            "│ Total_Points >= 19 ┆ 3029  │\n",
            "└────────────────────┴───────┘\n"
          ]
        }
      ],
      "source": [
        "# Most commonly rejected criteria\n",
        "print(\"\\nTop 20 most commonly rejected criteria:\")\n",
        "all_rejected = result_df.select(pl.col(\"Rejected_Criteria\").explode().alias(\"criterion\")).drop_nulls()\n",
        "rejected_counts = all_rejected.group_by(\"criterion\").agg(pl.len().alias(\"count\")).sort(\"count\", descending=True)\n",
        "print(rejected_counts.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Deduplication Impact:\n",
            "============================================================\n",
            "Total criteria before dedup: 447,004\n",
            "Total criteria after dedup:  363,818\n",
            "Criteria removed by dedup:   83,186 (18.6%)\n",
            "\n",
            "Rows affected by deduplication: 54,478\n"
          ]
        }
      ],
      "source": [
        "# Deduplication impact\n",
        "print(\"\\nDeduplication Impact:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Compare: base_rules + accepted vs merged (after dedup)\n",
        "dedup_stats = stats_df.with_columns([\n",
        "    (pl.col(\"n_base\") + pl.col(\"n_accepted\")).alias(\"n_before_dedup\"),\n",
        "]).with_columns([\n",
        "    (pl.col(\"n_before_dedup\") - pl.col(\"n_merged\")).alias(\"n_removed_by_dedup\"),\n",
        "])\n",
        "\n",
        "total_before = dedup_stats.select(pl.col(\"n_before_dedup\").sum()).item()\n",
        "total_after = dedup_stats.select(pl.col(\"n_merged\").sum()).item()\n",
        "total_removed = dedup_stats.select(pl.col(\"n_removed_by_dedup\").sum()).item()\n",
        "\n",
        "print(f\"Total criteria before dedup: {total_before:,}\")\n",
        "print(f\"Total criteria after dedup:  {total_after:,}\")\n",
        "if total_before > 0:\n",
        "    print(f\"Criteria removed by dedup:   {total_removed:,} ({100*total_removed/total_before:.1f}%)\")\n",
        "\n",
        "# Rows where dedup had an effect\n",
        "affected_rows = dedup_stats.filter(pl.col(\"n_removed_by_dedup\") > 0).height\n",
        "print(f\"\\nRows affected by deduplication: {affected_rows:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving to E:\\bridge\\data\\bbo\\bidding\\bbo_bt_merged_rules.parquet...\n",
            "  Saved 66,814 rows\n",
            "  File size: 8.83 MB\n"
          ]
        }
      ],
      "source": [
        "# Select final columns to save\n",
        "final_cols = [\n",
        "    \"step_auction\",\n",
        "    \"bt_index\",\n",
        "    \"seat\",\n",
        "    \"prefix\",\n",
        "    \"next_bid\",\n",
        "    \"pos_count\",\n",
        "    \"neg_count\",\n",
        "    \"base_rules\",\n",
        "    \"discovered_rules\",\n",
        "    \"criteria_with_metrics\",\n",
        "    \"Accepted_Criteria\",\n",
        "    \"Rejected_Criteria\",\n",
        "    \"Merged_Rules\",\n",
        "    \"top_lift\",\n",
        "    \"bt_row_found\",\n",
        "]\n",
        "\n",
        "# Filter to existing columns\n",
        "save_cols = [c for c in final_cols if c in result_df.columns]\n",
        "output_df = result_df.select(save_cols)\n",
        "\n",
        "# Ensure output directory exists\n",
        "OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Saving to {OUTPUT_FILE}...\")\n",
        "output_df.write_parquet(OUTPUT_FILE)\n",
        "\n",
        "file_size_mb = OUTPUT_FILE.stat().st_size / (1024 * 1024)\n",
        "print(f\"  Saved {output_df.height:,} rows\")\n",
        "print(f\"  File size: {file_size_mb:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "SUMMARY\n",
            "============================================================\n",
            "\n",
            "Thresholds used:\n",
            "  MIN_LIFT: 1.5\n",
            "  MIN_POS_RATE: 50%\n",
            "  MIN_POS_COUNT: 50\n",
            "  MAX_NEG_RATE: 80%\n",
            "  HIGH_CONFIDENCE_POS_RATE: 98%\n",
            "\n",
            "Results:\n",
            "  Total rows: 66,814\n",
            "  Rows with accepted criteria: 60,351\n",
            "  Total accepted criteria: 124,453\n",
            "  Total rejected criteria: 209,321\n",
            "  Criteria removed by dedup: 83,186\n",
            "\n",
            "Output: E:\\bridge\\data\\bbo\\bidding\\bbo_bt_merged_rules.parquet\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nThresholds used:\")\n",
        "print(f\"  MIN_LIFT: {MIN_LIFT}\")\n",
        "print(f\"  MIN_POS_RATE: {MIN_POS_RATE:.0%}\")\n",
        "print(f\"  MIN_POS_COUNT: {MIN_POS_COUNT}\")\n",
        "print(f\"  MAX_NEG_RATE: {MAX_NEG_RATE:.0%}\")\n",
        "print(f\"  HIGH_CONFIDENCE_POS_RATE: {HIGH_CONFIDENCE_POS_RATE:.0%}\")\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"  Total rows: {result_df.height:,}\")\n",
        "print(f\"  Rows with accepted criteria: {stats_df.filter(pl.col('n_accepted') > 0).height:,}\")\n",
        "print(f\"  Total accepted criteria: {all_accepted.height:,}\")\n",
        "print(f\"  Total rejected criteria: {all_rejected.height:,}\")\n",
        "print(f\"  Criteria removed by dedup: {total_removed:,}\")\n",
        "print(f\"\\nOutput: {OUTPUT_FILE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "EXPORT ANALYSIS REPORT\n",
            "================================================================================\n",
            "\n",
            "✓ Excel report saved: c:\\sw\\bridge\\ML-Contract-Bridge\\src\\BBO_GIB_Bidding_Playground\\bbo_bt_filter_analysis_20260107_112217.xlsx\n",
            "\n",
            "  Sheets created (all sorted by auction):\n",
            "    1. Summary - 10 metrics\n",
            "    2. Accepted_Criteria - 124,453 criteria\n",
            "    3. Rejected_Criteria - 209,321 criteria\n",
            "    4. New_Rules - 41,267 new rules\n",
            "    5. Auction_Summary - 66,814 auctions\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# EXPORT ANALYSIS REPORT\n",
        "# =============================================================================\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "REPORT_DIR = Path(\".\")  # Current directory\n",
        "REPORT_XLSX = REPORT_DIR / f\"bbo_bt_filter_analysis_{timestamp}.xlsx\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"EXPORT ANALYSIS REPORT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Prepare summary DataFrame\n",
        "summary_data = {\n",
        "    \"Metric\": [\n",
        "        \"MIN_LIFT\", \"MIN_POS_RATE\", \"MIN_POS_COUNT\", \"MAX_NEG_RATE\", \"HIGH_CONFIDENCE_POS_RATE\",\n",
        "        \"Total Rows\", \"Rows with Accepted Criteria\", \"Total Accepted\", \"Total Rejected\", \"Removed by Dedup\"\n",
        "    ],\n",
        "    \"Value\": [\n",
        "        str(MIN_LIFT), f\"{MIN_POS_RATE:.0%}\", str(MIN_POS_COUNT), f\"{MAX_NEG_RATE:.0%}\", f\"{HIGH_CONFIDENCE_POS_RATE:.0%}\",\n",
        "        str(result_df.height), str(stats_df.filter(pl.col('n_accepted') > 0).height),\n",
        "        str(all_accepted.height), str(all_rejected.height), str(total_removed)\n",
        "    ]\n",
        "}\n",
        "summary_df = pl.DataFrame(summary_data)\n",
        "\n",
        "# Accepted criteria with details - sorted by auction\n",
        "accepted_details_df = result_df.select([\n",
        "    \"step_auction\", \"seat\", \"prefix\", \"next_bid\",\n",
        "    pl.col(\"Accepted_Criteria\").alias(\"criteria\")\n",
        "]).explode(\"criteria\").drop_nulls().sort(\"step_auction\")\n",
        "\n",
        "if \"criteria_with_metrics\" in result_df.columns:\n",
        "    metrics_df = result_df.select([\n",
        "        \"step_auction\",\n",
        "        pl.col(\"criteria_with_metrics\").alias(\"metrics\")\n",
        "    ]).explode(\"metrics\").drop_nulls()\n",
        "    \n",
        "    if metrics_df.height > 0:\n",
        "        metrics_parsed = metrics_df.with_columns([\n",
        "            pl.col(\"metrics\").struct.field(\"criterion\").alias(\"criteria\"),\n",
        "            pl.col(\"metrics\").struct.field(\"pos_rate\").alias(\"pos_rate\"),\n",
        "            pl.col(\"metrics\").struct.field(\"neg_rate\").alias(\"neg_rate\"),\n",
        "            pl.col(\"metrics\").struct.field(\"lift\").alias(\"lift\"),\n",
        "        ]).drop(\"metrics\")\n",
        "        \n",
        "        accepted_details_df = accepted_details_df.join(\n",
        "            metrics_parsed, on=[\"step_auction\", \"criteria\"], how=\"left\"\n",
        "        ).sort(\"step_auction\")\n",
        "\n",
        "# Rejected criteria with details - sorted by auction\n",
        "rejected_details_df = result_df.select([\n",
        "    \"step_auction\", \"seat\", \"prefix\", \"next_bid\",\n",
        "    pl.col(\"Rejected_Criteria\").alias(\"criteria\")\n",
        "]).explode(\"criteria\").drop_nulls().sort(\"step_auction\")\n",
        "\n",
        "# New rules (criteria in Merged but not in base) - sorted by auction\n",
        "new_rules_df_export = result_df.select([\n",
        "    \"step_auction\", \"seat\", \"prefix\", \"next_bid\",\n",
        "    pl.col(\"Merged_Rules\").alias(\"merged\"),\n",
        "    pl.col(\"base_rules\").alias(\"base\"),\n",
        "]).with_columns([\n",
        "    pl.col(\"merged\").list.set_difference(pl.col(\"base\")).alias(\"new_rules\")\n",
        "]).explode(\"new_rules\").drop_nulls().select([\n",
        "    \"step_auction\", \"seat\", \"prefix\", \"next_bid\", \"new_rules\"\n",
        "]).sort(\"step_auction\")\n",
        "\n",
        "# Per-auction summary - sorted by auction\n",
        "auction_summary = stats_df.select([\n",
        "    \"step_auction\", \"n_base\", \"n_discovered\", \"n_accepted\", \"n_rejected\", \"n_merged\"\n",
        "]).sort(\"step_auction\")\n",
        "\n",
        "# Helper function to autosize columns\n",
        "def autosize_columns(writer, sheet_name, df_pandas):\n",
        "    \"\"\"Set column widths to max of header and longest value.\"\"\"\n",
        "    worksheet = writer.sheets[sheet_name]\n",
        "    for idx, col in enumerate(df_pandas.columns):\n",
        "        # Get max length of column name and values\n",
        "        max_len = len(str(col))\n",
        "        if len(df_pandas) > 0:\n",
        "            # Sample up to 10000 rows for performance\n",
        "            sample = df_pandas[col].head(10000).astype(str)\n",
        "            max_val_len = sample.str.len().max()\n",
        "            max_len = max(max_len, max_val_len)\n",
        "        # Add a little padding and cap at reasonable width\n",
        "        worksheet.set_column(idx, idx, min(max_len + 2, 50))\n",
        "\n",
        "# Write to Excel with multiple sheets using pandas\n",
        "with pd.ExcelWriter(REPORT_XLSX, engine=\"xlsxwriter\") as writer:\n",
        "    # Summary sheet\n",
        "    summary_pd = summary_df.to_pandas()\n",
        "    summary_pd.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "    autosize_columns(writer, \"Summary\", summary_pd)\n",
        "    \n",
        "    # Accepted criteria sheet\n",
        "    if accepted_details_df.height > 0:\n",
        "        accepted_pd = accepted_details_df.to_pandas()\n",
        "        accepted_pd.to_excel(writer, sheet_name=\"Accepted_Criteria\", index=False)\n",
        "        autosize_columns(writer, \"Accepted_Criteria\", accepted_pd)\n",
        "    \n",
        "    # Rejected criteria sheet\n",
        "    if rejected_details_df.height > 0:\n",
        "        rejected_pd = rejected_details_df.to_pandas()\n",
        "        rejected_pd.to_excel(writer, sheet_name=\"Rejected_Criteria\", index=False)\n",
        "        autosize_columns(writer, \"Rejected_Criteria\", rejected_pd)\n",
        "    \n",
        "    # New rules sheet\n",
        "    if new_rules_df_export.height > 0:\n",
        "        new_rules_pd = new_rules_df_export.to_pandas()\n",
        "        new_rules_pd.to_excel(writer, sheet_name=\"New_Rules\", index=False)\n",
        "        autosize_columns(writer, \"New_Rules\", new_rules_pd)\n",
        "    \n",
        "    # Auction summary sheet\n",
        "    auction_pd = auction_summary.to_pandas()\n",
        "    auction_pd.to_excel(writer, sheet_name=\"Auction_Summary\", index=False)\n",
        "    autosize_columns(writer, \"Auction_Summary\", auction_pd)\n",
        "\n",
        "print(f\"\\n✓ Excel report saved: {REPORT_XLSX.absolute()}\")\n",
        "print(f\"\\n  Sheets created (all sorted by auction):\")\n",
        "print(f\"    1. Summary - {summary_df.height} metrics\")\n",
        "print(f\"    2. Accepted_Criteria - {accepted_details_df.height:,} criteria\")\n",
        "print(f\"    3. Rejected_Criteria - {rejected_details_df.height:,} criteria\")\n",
        "print(f\"    4. New_Rules - {new_rules_df_export.height:,} new rules\")\n",
        "print(f\"    5. Auction_Summary - {auction_summary.height:,} auctions\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Program elapsed time in seconds: 1074.4085602760315\n",
            "2026-01-07 11:22:33\n"
          ]
        }
      ],
      "source": [
        "print('Program elapsed time in seconds:', time.time()-program_start_time)\n",
        "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
