{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bulk Learn New Rules Per Step\n",
        "\n",
        "Takes 2h30m/3h. 1.2TB memory/pagefile.\n",
        "\n",
        "Discover high-correlation criteria (\"New_Rules\") for BT rows using actual auctions as ground truth.\n",
        "\n",
        "**Goal**: For each (auction_prefix, next_bid) combination, find bitmap criteria that best separate:\n",
        "- **Positives**: Deals where actual auction has this exact (prefix, next_bid)\n",
        "- **Negatives**: Deals where auction has same prefix but DIFFERENT next_bid\n",
        "\n",
        "**Output**: `E:/bridge/data/bbo/bidding/bbo_bt_new_rules.parquet` with `New_Rules: List(Utf8)` column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-27 12:06:50\n",
            "Configuration:\n",
            "  MAX_DEALS: all\n",
            "  MIN_POS_SAMPLES: 100\n",
            "  MIN_SUPPORT: 0.1\n",
            "  MIN_LIFT: 1.3\n",
            "  TOP_K_CRITERIA: 6\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "import gc\n",
        "import time\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "program_start_time = time.time()\n",
        "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
        "\n",
        "# Paths\n",
        "DEALS_FILE = Path(\"E:/bridge/data/bbo/data/bbo_mldf_augmented.parquet\")\n",
        "BT_FILE = Path(\"E:/bridge/data/bbo/bidding/bbo_bt_seat1.parquet\")\n",
        "BITMAP_FILE = Path(\"E:/bridge/data/bbo/data/bbo_mldf_augmented_criteria_bitmaps.parquet\")\n",
        "OUTPUT_FILE = Path(\"E:/bridge/data/bbo/bidding/bbo_bt_new_rules.parquet\")\n",
        "\n",
        "# Column constants\n",
        "AGG_EXPR_COLS = [f\"Agg_Expr_Seat_{i}\" for i in range(1, 5)]\n",
        "\n",
        "# Processing parameters\n",
        "MAX_DEALS = None  # Set to int for testing, None for all deals\n",
        "MIN_POS_SAMPLES = 100  # Minimum positive samples to learn rules\n",
        "MIN_SUPPORT = 0.10  # Minimum criterion support within positives\n",
        "MIN_LIFT = 1.3  # Minimum lift to consider criterion valuable\n",
        "TOP_K_CRITERIA = 6  # Max criteria to discover per step\n",
        "\n",
        "DIRECTIONS = [\"N\", \"E\", \"S\", \"W\"]\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  MAX_DEALS: {MAX_DEALS or 'all'}\")\n",
        "print(f\"  MIN_POS_SAMPLES: {MIN_POS_SAMPLES}\")\n",
        "print(f\"  MIN_SUPPORT: {MIN_SUPPORT}\")\n",
        "print(f\"  MIN_LIFT: {MIN_LIFT}\")\n",
        "print(f\"  TOP_K_CRITERIA: {TOP_K_CRITERIA}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1: Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper: format elapsed time\n",
        "def fmt_elapsed(seconds: float) -> str:\n",
        "    if seconds < 60:\n",
        "        return f\"{seconds:.1f}s\"\n",
        "    elif seconds < 3600:\n",
        "        return f\"{seconds/60:.1f}m\"\n",
        "    else:\n",
        "        return f\"{seconds/3600:.1f}h\"\n",
        "\n",
        "def fmt_eta(done: int, total: int, elapsed: float) -> str:\n",
        "    if done <= 0:\n",
        "        return \"?\"\n",
        "    rate = done / elapsed if elapsed > 0 else 0\n",
        "    remaining = total - done\n",
        "    eta_s = remaining / rate if rate > 0 else 0\n",
        "    return fmt_elapsed(eta_s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BT...\n",
            "  Loaded 461,681,310 BT rows in 6.1m\n",
            "  Columns: ['bt_index', 'Auction', 'seat', 'Expr', 'Agg_Expr_Seat_1', 'Agg_Expr_Seat_2', 'Agg_Expr_Seat_3', 'Agg_Expr_Seat_4', '_auction_lower']\n"
          ]
        }
      ],
      "source": [
        "# takes 6m for 461M rows\n",
        "# Load BT (for existing criteria and bt_index lookup)\n",
        "print(\"Loading BT...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "bt_cols = [\"bt_index\", \"Auction\", \"seat\", \"Expr\"] + AGG_EXPR_COLS\n",
        "bt_schema = pl.scan_parquet(BT_FILE).collect_schema()\n",
        "bt_cols_available = [c for c in bt_cols if c in bt_schema.names()]\n",
        "\n",
        "bt_df = pl.scan_parquet(BT_FILE).select(bt_cols_available).collect()\n",
        "bt_df = bt_df.with_columns(pl.col(\"Auction\").cast(pl.Utf8).str.to_lowercase().alias(\"_auction_lower\"))\n",
        "\n",
        "print(f\"  Loaded {bt_df.height:,} BT rows in {fmt_elapsed(time.perf_counter() - t0)}\")\n",
        "print(f\"  Columns: {bt_df.columns}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading deals...\n",
            "  Loaded 15,994,827 deals in 2.7s\n"
          ]
        }
      ],
      "source": [
        "# takes 5s\n",
        "#  Load deals\n",
        "print(\"Loading deals...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "deal_cols = [\"index\", \"Dealer\", \"bid\"]\n",
        "deals_scan = pl.scan_parquet(DEALS_FILE).select(deal_cols)\n",
        "if MAX_DEALS:\n",
        "    deals_scan = deals_scan.head(MAX_DEALS)\n",
        "deals_df = deals_scan.collect()\n",
        "\n",
        "print(f\"  Loaded {deals_df.height:,} deals in {fmt_elapsed(time.perf_counter() - t0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building candidate criteria pool...\n",
            "  Found 223 candidate criteria from BT Agg_Expr columns\n"
          ]
        }
      ],
      "source": [
        "# takes 18m\n",
        "# Build candidate criteria pool from BT Agg_Expr columns\n",
        "print(\"Building candidate criteria pool...\")\n",
        "\n",
        "# Conservative pattern: HCP, Total_Points, SL_* with comparison operators\n",
        "CAND_RE = re.compile(r\"^(HCP|Total_Points|SL_[SHDC])\\s*(>=|<=|==|!=|>|<)\\s*(\\d+)\\s*$\")\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class CandidateCriterion:\n",
        "    text: str  # e.g. \"HCP >= 30\", \"SL_S >= 5\"\n",
        "    field: str  # \"HCP\" | \"Total_Points\" | \"SL_S\" etc\n",
        "    op: str\n",
        "    value: int\n",
        "\n",
        "def parse_candidate(c: str) -> Optional[CandidateCriterion]:\n",
        "    s = (c or \"\").strip()\n",
        "    m = CAND_RE.match(s)\n",
        "    if not m:\n",
        "        return None\n",
        "    field, op, val_s = m.group(1), m.group(2), m.group(3)\n",
        "    try:\n",
        "        v = int(val_s)\n",
        "    except Exception:\n",
        "        return None\n",
        "    return CandidateCriterion(text=s, field=field, op=op, value=v)\n",
        "\n",
        "def candidate_to_bitmap_col(crit: CandidateCriterion, bidder_dir: str) -> str:\n",
        "    \"\"\"Map directionless criterion to a directional bitmap parquet column name.\"\"\"\n",
        "    d = bidder_dir.upper()\n",
        "    if crit.field in (\"HCP\", \"Total_Points\"):\n",
        "        return f\"DIR_{d}_{crit.field}_{d} {crit.op} {crit.value}\"\n",
        "    if crit.field.startswith(\"SL_\"):\n",
        "        suit = crit.field.split(\"_\", 1)[1]  # S/H/D/C\n",
        "        return f\"DIR_{d}_SL_{d}_{suit} {crit.op} {crit.value}\"\n",
        "    return \"\"\n",
        "\n",
        "# Extract all criteria strings from BT\n",
        "cand_map: Dict[str, CandidateCriterion] = {}\n",
        "for col in AGG_EXPR_COLS:\n",
        "    if col not in bt_df.columns:\n",
        "        continue\n",
        "    try:\n",
        "        vals = bt_df.select(pl.col(col).explode()).get_column(col).drop_nulls().unique().to_list()\n",
        "    except Exception:\n",
        "        continue\n",
        "    for v in vals:\n",
        "        if v is None:\n",
        "            continue\n",
        "        cc = parse_candidate(str(v))\n",
        "        if cc is not None:\n",
        "            cand_map[cc.text] = cc\n",
        "\n",
        "candidates = list(cand_map.values())\n",
        "print(f\"  Found {len(candidates)} candidate criteria from BT Agg_Expr columns\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading bitmap schema...\n",
            "  Filtered to 201 candidates with bitmap columns\n",
            "  Sample candidates: ['Total_Points <= 3', 'SL_S >= 6', 'HCP >= 32', 'HCP >= 8', 'Total_Points >= 20', 'SL_H >= 6', 'Total_Points <= 29', 'HCP <= 23', 'Total_Points >= 15', 'HCP >= 12']\n"
          ]
        }
      ],
      "source": [
        "# Load bitmap schema and filter candidates to those with bitmap columns\n",
        "print(\"Loading bitmap schema...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "bitmap_schema = pl.scan_parquet(BITMAP_FILE).collect_schema()\n",
        "bitmap_cols_set = set(bitmap_schema.names())\n",
        "\n",
        "# Filter candidates: keep only those with at least one direction having a bitmap column\n",
        "valid_candidates: List[CandidateCriterion] = []\n",
        "for c in candidates:\n",
        "    for d in DIRECTIONS:\n",
        "        col = candidate_to_bitmap_col(c, d)\n",
        "        if col and col in bitmap_cols_set:\n",
        "            valid_candidates.append(c)\n",
        "            break\n",
        "\n",
        "candidates = valid_candidates\n",
        "print(f\"  Filtered to {len(candidates)} candidates with bitmap columns\")\n",
        "print(f\"  Sample candidates: {[c.text for c in candidates[:10]]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2: Extract Auction Steps from Deals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def canon_token(t: Any) -> str:\n",
        "    s = \"\" if t is None else str(t).strip()\n",
        "    return s.lower()\n",
        "\n",
        "def parse_bid_list(bids: Any) -> Tuple[int, List[str]]:\n",
        "    \"\"\"Parse bid column into (leading_passes, seat1_tokens).\"\"\"\n",
        "    if bids is None:\n",
        "        return 0, []\n",
        "    if isinstance(bids, pl.Series):\n",
        "        bids = bids.to_list()\n",
        "    if not isinstance(bids, list):\n",
        "        s = canon_token(bids)\n",
        "        if not s:\n",
        "            return 0, []\n",
        "        tokens = [t for t in s.split(\"-\") if t != \"\"]\n",
        "    else:\n",
        "        tokens = [canon_token(x) for x in bids if canon_token(x) != \"\"]\n",
        "    \n",
        "    lp = 0\n",
        "    while lp < len(tokens) and tokens[lp] == \"p\":\n",
        "        lp += 1\n",
        "    seat1_tokens = tokens[lp:]\n",
        "    return lp, seat1_tokens\n",
        "\n",
        "def bidder_direction_for_token(dealer: str, leading_passes: int, token_idx_in_seat1: int) -> str:\n",
        "    \"\"\"Get direction of bidder making the token at position token_idx_in_seat1.\"\"\"\n",
        "    d = (dealer or \"N\").upper()\n",
        "    dealer_i = DIRECTIONS.index(d) if d in DIRECTIONS else 0\n",
        "    original_token_idx = leading_passes + token_idx_in_seat1\n",
        "    return DIRECTIONS[(dealer_i + original_token_idx) % 4]\n",
        "\n",
        "def seat_for_token(token_idx_in_seat1: int) -> int:\n",
        "    \"\"\"Get seat number (1-4) for token at position token_idx_in_seat1.\"\"\"\n",
        "    return (token_idx_in_seat1 % 4) + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting auction steps from deals...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f91ae2ac8654105a301db888c08a979",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing deals:   0%|          | 0/15994827 [00:00<?, ?deal/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Extracted 153,739,362 step tuples from 15,994,827 deals in 2.6m\n",
            "  Rate: 1,002,305 tuples/sec\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# takes 2m15s\n",
        "# Extract all (prefix, next_bid, seat, bidder_dir, deal_idx) tuples from deals\n",
        "print(\"Extracting auction steps from deals...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "# Pre-extract columns\n",
        "deal_indices = deals_df.get_column(\"index\").to_list()\n",
        "dealers = deals_df.get_column(\"Dealer\").to_list()\n",
        "bids_col = deals_df.get_column(\"bid\").to_list()\n",
        "\n",
        "# Accumulate step data\n",
        "step_data: List[Tuple[str, str, int, str, int]] = []  # (prefix, next_bid, seat, bidder_dir, deal_idx)\n",
        "\n",
        "n_deals = len(deal_indices)\n",
        "last_print = time.perf_counter()\n",
        "\n",
        "for i in tqdm(range(n_deals), desc=\"Parsing deals\", unit=\"deal\"):\n",
        "    dealer = dealers[i] or \"N\"\n",
        "    lp, seat1_tokens = parse_bid_list(bids_col[i])\n",
        "    \n",
        "    if len(seat1_tokens) < 1:\n",
        "        continue\n",
        "    \n",
        "    # Generate all step pairs for this deal\n",
        "    for tok_idx in range(len(seat1_tokens)):\n",
        "        prefix = \"-\".join(seat1_tokens[:tok_idx]) if tok_idx > 0 else \"\"\n",
        "        next_bid = seat1_tokens[tok_idx]\n",
        "        seat = seat_for_token(tok_idx)\n",
        "        bidder_dir = bidder_direction_for_token(dealer, lp, tok_idx)\n",
        "        step_data.append((prefix, next_bid, seat, bidder_dir, i))  # use row index i, not deal_idx\n",
        "\n",
        "elapsed = time.perf_counter() - t0\n",
        "print(f\"  Extracted {len(step_data):,} step tuples from {n_deals:,} deals in {fmt_elapsed(elapsed)}\")\n",
        "print(f\"  Rate: {len(step_data)/elapsed:,.0f} tuples/sec\")\n",
        "\n",
        "# Free deals_df memory - no longer needed\n",
        "del deals_df, deal_indices, dealers, bids_col\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building step DataFrame and prefix index (single pass)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "137e97c4463940adb22504c68dfbb3ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing steps:   0%|          | 0/153739362 [00:00<?, ?row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Built steps_df: 153,739,362 rows\n",
            "  Built prefix_index: 3,371,488 prefixes, 4,172,691 (prefix, next_bid) pairs\n",
            "  Time: 4.1m\n"
          ]
        }
      ],
      "source": [
        "# takes 4m (builds BOTH steps_df AND prefix_index in single pass)\n",
        "# This avoids double iteration over 153M items\n",
        "print(\"Building step DataFrame and prefix index (single pass)...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "# Single pass: build both lists for DataFrame AND prefix_index simultaneously\n",
        "prefixes: List[str] = []\n",
        "next_bids_list: List[str] = []\n",
        "seats_list: List[int] = []\n",
        "bidder_dirs_list: List[str] = []\n",
        "row_idxs: List[int] = []\n",
        "\n",
        "# Also build prefix_index during the same pass\n",
        "prefix_index: Dict[str, Dict[str, Dict[str, List]]] = defaultdict(lambda: defaultdict(lambda: {\"row_indices\": [], \"bidder_dirs\": []}))\n",
        "\n",
        "for s in tqdm(step_data, desc=\"Processing steps\", unit=\"row\"):\n",
        "    p, nb, seat, bd, ridx = s\n",
        "    # For DataFrame\n",
        "    prefixes.append(p)\n",
        "    next_bids_list.append(nb)\n",
        "    seats_list.append(seat)\n",
        "    bidder_dirs_list.append(bd)\n",
        "    row_idxs.append(ridx)\n",
        "    # For prefix_index\n",
        "    prefix_index[p][nb][\"row_indices\"].append(ridx)\n",
        "    prefix_index[p][nb][\"bidder_dirs\"].append(bd)\n",
        "\n",
        "# Build DataFrame\n",
        "steps_df = pl.DataFrame({\n",
        "    \"prefix\": prefixes,\n",
        "    \"next_bid\": next_bids_list,\n",
        "    \"seat\": seats_list,\n",
        "    \"bidder_dir\": bidder_dirs_list,\n",
        "    \"_row_idx\": row_idxs,\n",
        "})\n",
        "\n",
        "# Convert prefix_index to regular dict for faster access\n",
        "prefix_index = {k: dict(v) for k, v in prefix_index.items()}\n",
        "\n",
        "# Free memory\n",
        "del step_data, prefixes, next_bids_list, seats_list, bidder_dirs_list, row_idxs\n",
        "gc.collect()\n",
        "\n",
        "elapsed = time.perf_counter() - t0\n",
        "print(f\"  Built steps_df: {steps_df.height:,} rows\")\n",
        "print(f\"  Built prefix_index: {len(prefix_index):,} prefixes, {sum(len(v) for v in prefix_index.values()):,} (prefix, next_bid) pairs\")\n",
        "print(f\"  Time: {fmt_elapsed(elapsed)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prefix_index already built: 3,371,488 prefixes, 4,172,691 (prefix, next_bid) pairs\n"
          ]
        }
      ],
      "source": [
        "# SKIPPED: prefix_index now built in Cell 11 (single pass optimization)\n",
        "# Verify it exists\n",
        "print(f\"prefix_index already built: {len(prefix_index):,} prefixes, {sum(len(v) for v in prefix_index.values()):,} (prefix, next_bid) pairs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 3: Identify Groups with Sufficient Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grouping by (prefix, next_bid)...\n",
            "  Found 4,172,691 unique (prefix, next_bid) groups in 4.6s\n",
            "  Top 20 groups by count:\n",
            "shape: (20, 4)\n",
            "┌─────────┬──────────┬───────────┬──────┐\n",
            "│ prefix  ┆ next_bid ┆ pos_count ┆ seat │\n",
            "│ ---     ┆ ---      ┆ ---       ┆ ---  │\n",
            "│ str     ┆ str      ┆ u64       ┆ i64  │\n",
            "╞═════════╪══════════╪═══════════╪══════╡\n",
            "│         ┆ 1d       ┆ 3507593   ┆ 1    │\n",
            "│         ┆ 1c       ┆ 3446023   ┆ 1    │\n",
            "│         ┆ 1n       ┆ 2518162   ┆ 1    │\n",
            "│         ┆ 1s       ┆ 2497723   ┆ 1    │\n",
            "│         ┆ 1h       ┆ 2363106   ┆ 1    │\n",
            "│ …       ┆ …        ┆ …         ┆ …    │\n",
            "│ 1d-p-1h ┆ p        ┆ 607804    ┆ 4    │\n",
            "│ 1c-p    ┆ 1s       ┆ 590588    ┆ 3    │\n",
            "│ 1n-p    ┆ 2c       ┆ 590415    ┆ 3    │\n",
            "│ 1n-p-2c ┆ p        ┆ 567114    ┆ 4    │\n",
            "│ 1n-p    ┆ p        ┆ 560160    ┆ 3    │\n",
            "└─────────┴──────────┴───────────┴──────┘\n"
          ]
        }
      ],
      "source": [
        "# takes 5s\n",
        "# Group by (prefix, next_bid) and count\n",
        "print(\"Grouping by (prefix, next_bid)...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "group_counts = (\n",
        "    steps_df\n",
        "    .group_by([\"prefix\", \"next_bid\"])\n",
        "    .agg([\n",
        "        pl.len().alias(\"pos_count\"),\n",
        "        pl.col(\"seat\").first().alias(\"seat\"),  # seat is deterministic from prefix length\n",
        "    ])\n",
        "    .sort(\"pos_count\", descending=True)\n",
        ")\n",
        "\n",
        "print(f\"  Found {group_counts.height:,} unique (prefix, next_bid) groups in {fmt_elapsed(time.perf_counter() - t0)}\")\n",
        "print(f\"  Top 20 groups by count:\")\n",
        "print(group_counts.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing prefix totals for negative sets...\n",
            "  Computed in 3.8s\n",
            "shape: (10, 6)\n",
            "┌────────┬──────────┬───────────┬──────┬──────────────┬───────────┐\n",
            "│ prefix ┆ next_bid ┆ pos_count ┆ seat ┆ prefix_total ┆ neg_count │\n",
            "│ ---    ┆ ---      ┆ ---       ┆ ---  ┆ ---          ┆ ---       │\n",
            "│ str    ┆ str      ┆ u64       ┆ i64  ┆ u64          ┆ u64       │\n",
            "╞════════╪══════════╪═══════════╪══════╪══════════════╪═══════════╡\n",
            "│        ┆ 1d       ┆ 3507593   ┆ 1    ┆ 15994827     ┆ 12487234  │\n",
            "│        ┆ 1c       ┆ 3446023   ┆ 1    ┆ 15994827     ┆ 12548804  │\n",
            "│        ┆ 1n       ┆ 2518162   ┆ 1    ┆ 15994827     ┆ 13476665  │\n",
            "│        ┆ 1s       ┆ 2497723   ┆ 1    ┆ 15994827     ┆ 13497104  │\n",
            "│        ┆ 1h       ┆ 2363106   ┆ 1    ┆ 15994827     ┆ 13631721  │\n",
            "│ 1n     ┆ p        ┆ 2152534   ┆ 2    ┆ 2517958      ┆ 365424    │\n",
            "│ 1d     ┆ p        ┆ 2096452   ┆ 2    ┆ 3505293      ┆ 1408841   │\n",
            "│ 1c     ┆ p        ┆ 1905720   ┆ 2    ┆ 3443818      ┆ 1538098   │\n",
            "│ 1s     ┆ p        ┆ 1808043   ┆ 2    ┆ 2496095      ┆ 688052    │\n",
            "│ 1h     ┆ p        ┆ 1524545   ┆ 2    ┆ 2361597      ┆ 837052    │\n",
            "└────────┴──────────┴───────────┴──────┴──────────────┴───────────┘\n",
            "  Freed steps_df memory\n"
          ]
        }
      ],
      "source": [
        "# takes 10s\n",
        "# For each prefix, compute total deals (for negative set calculation)\n",
        "print(\"Computing prefix totals for negative sets...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "prefix_totals = (\n",
        "    steps_df\n",
        "    .group_by(\"prefix\")\n",
        "    .agg(pl.len().alias(\"prefix_total\"))\n",
        ")\n",
        "\n",
        "# Join to get neg_count = prefix_total - pos_count\n",
        "group_counts = (\n",
        "    group_counts\n",
        "    .join(prefix_totals, on=\"prefix\", how=\"left\")\n",
        "    .with_columns(\n",
        "        (pl.col(\"prefix_total\") - pl.col(\"pos_count\")).alias(\"neg_count\")\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"  Computed in {fmt_elapsed(time.perf_counter() - t0)}\")\n",
        "print(group_counts.head(10))\n",
        "\n",
        "# Free steps_df memory - no longer needed (prefix_index has all we need for scoring)\n",
        "del steps_df\n",
        "gc.collect()\n",
        "print(\"  Freed steps_df memory\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Groups with >= 100 positives and > 0 negatives: 66,927\n",
            "Top 10 learnable groups:\n",
            "shape: (10, 6)\n",
            "┌────────┬──────────┬───────────┬──────┬──────────────┬───────────┐\n",
            "│ prefix ┆ next_bid ┆ pos_count ┆ seat ┆ prefix_total ┆ neg_count │\n",
            "│ ---    ┆ ---      ┆ ---       ┆ ---  ┆ ---          ┆ ---       │\n",
            "│ str    ┆ str      ┆ u64       ┆ i64  ┆ u64          ┆ u64       │\n",
            "╞════════╪══════════╪═══════════╪══════╪══════════════╪═══════════╡\n",
            "│        ┆ 1d       ┆ 3507593   ┆ 1    ┆ 15994827     ┆ 12487234  │\n",
            "│        ┆ 1c       ┆ 3446023   ┆ 1    ┆ 15994827     ┆ 12548804  │\n",
            "│        ┆ 1n       ┆ 2518162   ┆ 1    ┆ 15994827     ┆ 13476665  │\n",
            "│        ┆ 1s       ┆ 2497723   ┆ 1    ┆ 15994827     ┆ 13497104  │\n",
            "│        ┆ 1h       ┆ 2363106   ┆ 1    ┆ 15994827     ┆ 13631721  │\n",
            "│ 1n     ┆ p        ┆ 2152534   ┆ 2    ┆ 2517958      ┆ 365424    │\n",
            "│ 1d     ┆ p        ┆ 2096452   ┆ 2    ┆ 3505293      ┆ 1408841   │\n",
            "│ 1c     ┆ p        ┆ 1905720   ┆ 2    ┆ 3443818      ┆ 1538098   │\n",
            "│ 1s     ┆ p        ┆ 1808043   ┆ 2    ┆ 2496095      ┆ 688052    │\n",
            "│ 1h     ┆ p        ┆ 1524545   ┆ 2    ┆ 2361597      ┆ 837052    │\n",
            "└────────┴──────────┴───────────┴──────┴──────────────┴───────────┘\n"
          ]
        }
      ],
      "source": [
        "# Filter to groups with sufficient positive and negative samples\n",
        "learnable_groups = group_counts.filter(\n",
        "    (pl.col(\"pos_count\") >= MIN_POS_SAMPLES) &\n",
        "    (pl.col(\"neg_count\") > 0)\n",
        ").sort(\"pos_count\", descending=True)\n",
        "\n",
        "print(f\"Groups with >= {MIN_POS_SAMPLES} positives and > 0 negatives: {learnable_groups.height:,}\")\n",
        "print(f\"Top 10 learnable groups:\")\n",
        "print(learnable_groups.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 4: Load Bitmap Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Determining required bitmap columns...\n",
            "  Need 804 bitmap columns\n"
          ]
        }
      ],
      "source": [
        "# Determine which bitmap columns we need\n",
        "print(\"Determining required bitmap columns...\")\n",
        "\n",
        "required_bitmap_cols = set()\n",
        "for c in candidates:\n",
        "    for d in DIRECTIONS:\n",
        "        col = candidate_to_bitmap_col(c, d)\n",
        "        if col and col in bitmap_cols_set:\n",
        "            required_bitmap_cols.add(col)\n",
        "\n",
        "required_bitmap_cols = sorted(required_bitmap_cols)\n",
        "print(f\"  Need {len(required_bitmap_cols)} bitmap columns\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading bitmap data (804 columns)...\n",
            "  Loaded bitmap_df: (15994827, 804) in 0.8s\n",
            "Converting bitmap columns to numpy arrays...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d44b5c02867d459f915a65b3a11e5880",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Converting to numpy:   0%|          | 0/804 [00:00<?, ?col/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Converted 804 columns to numpy in 9.1s\n",
            "  Built lookup with 804 (criterion, direction) -> column mappings\n"
          ]
        }
      ],
      "source": [
        "# takes 15s\n",
        "#  Load bitmap data (only required columns)\n",
        "print(f\"Loading bitmap data ({len(required_bitmap_cols)} columns)...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "bitmap_scan = pl.scan_parquet(BITMAP_FILE).select(required_bitmap_cols)\n",
        "if MAX_DEALS:\n",
        "    bitmap_scan = bitmap_scan.head(MAX_DEALS)\n",
        "bitmap_df = bitmap_scan.collect()\n",
        "\n",
        "print(f\"  Loaded bitmap_df: {bitmap_df.shape} in {fmt_elapsed(time.perf_counter() - t0)}\")\n",
        "\n",
        "# CRITICAL OPTIMIZATION: Convert to numpy arrays for fast indexing\n",
        "# Polars .gather() is extremely slow when called millions of times\n",
        "print(\"Converting bitmap columns to numpy arrays...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "bitmap_arrays: Dict[str, np.ndarray] = {}\n",
        "for col in tqdm(bitmap_df.columns, desc=\"Converting to numpy\", unit=\"col\"):\n",
        "    bitmap_arrays[col] = bitmap_df[col].to_numpy()\n",
        "\n",
        "print(f\"  Converted {len(bitmap_arrays)} columns to numpy in {fmt_elapsed(time.perf_counter() - t0)}\")\n",
        "\n",
        "# Free Polars DataFrame memory - we only need numpy arrays now\n",
        "del bitmap_df\n",
        "gc.collect()\n",
        "\n",
        "# Build column lookup: (criterion_text, direction) -> column name\n",
        "col_lookup: Dict[Tuple[str, str], str] = {}\n",
        "for c in candidates:\n",
        "    for d in DIRECTIONS:\n",
        "        col = candidate_to_bitmap_col(c, d)\n",
        "        if col and col in bitmap_arrays:\n",
        "            col_lookup[(c.text, d)] = col\n",
        "\n",
        "print(f\"  Built lookup with {len(col_lookup)} (criterion, direction) -> column mappings\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 5: Compute Lift Scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_lift(pos_rate: float, neg_rate: float) -> float:\n",
        "    \"\"\"Compute lift = P(criterion | positive) / P(criterion | negative).\"\"\"\n",
        "    if neg_rate <= 0:\n",
        "        return float(\"inf\") if pos_rate > 0 else 1.0\n",
        "    return pos_rate / neg_rate\n",
        "\n",
        "def score_criteria_for_group_fast(\n",
        "    prefix: str,\n",
        "    next_bid: str,\n",
        "    prefix_index: Dict[str, Dict[str, Dict[str, List]]],\n",
        "    bitmap_arrays: Dict[str, np.ndarray],\n",
        "    candidates: List[CandidateCriterion],\n",
        "    col_lookup: Dict[Tuple[str, str], str],\n",
        ") -> List[Tuple[str, float, float, float]]:\n",
        "    \"\"\"\n",
        "    Score all candidate criteria for a (prefix, next_bid) group.\n",
        "    Uses prefix_index for O(1) lookups and numpy arrays for fast bitmap access.\n",
        "    \n",
        "    Returns list of (criterion_text, lift, pos_rate, neg_rate) sorted by lift descending.\n",
        "    \"\"\"\n",
        "    # O(1) lookup from pre-built index\n",
        "    prefix_data = prefix_index.get(prefix)\n",
        "    if not prefix_data:\n",
        "        return []\n",
        "    \n",
        "    pos_data = prefix_data.get(next_bid)\n",
        "    if not pos_data:\n",
        "        return []\n",
        "    \n",
        "    pos_row_indices = pos_data[\"row_indices\"]\n",
        "    pos_bidder_dirs = pos_data[\"bidder_dirs\"]\n",
        "    \n",
        "    if not pos_row_indices:\n",
        "        return []\n",
        "    \n",
        "    # Collect negative data (all other next_bids for this prefix)\n",
        "    neg_row_indices: List[int] = []\n",
        "    neg_bidder_dirs: List[str] = []\n",
        "    for nb, data in prefix_data.items():\n",
        "        if nb != next_bid:\n",
        "            neg_row_indices.extend(data[\"row_indices\"])\n",
        "            neg_bidder_dirs.extend(data[\"bidder_dirs\"])\n",
        "    \n",
        "    if not neg_row_indices:\n",
        "        return []\n",
        "    \n",
        "    # Group by bidder direction for efficient bitmap lookup\n",
        "    # Convert to numpy arrays for faster indexing\n",
        "    pos_by_dir: Dict[str, np.ndarray] = {}\n",
        "    neg_by_dir: Dict[str, np.ndarray] = {}\n",
        "    \n",
        "    for d in DIRECTIONS:\n",
        "        pos_by_dir[d] = np.array([idx for idx, dir in zip(pos_row_indices, pos_bidder_dirs) if dir == d], dtype=np.int64)\n",
        "        neg_by_dir[d] = np.array([idx for idx, dir in zip(neg_row_indices, neg_bidder_dirs) if dir == d], dtype=np.int64)\n",
        "    \n",
        "    results: List[Tuple[str, float, float, float]] = []\n",
        "    \n",
        "    for c in candidates:\n",
        "        pos_true = 0\n",
        "        pos_tot = 0\n",
        "        neg_true = 0\n",
        "        neg_tot = 0\n",
        "        \n",
        "        for d in DIRECTIONS:\n",
        "            col = col_lookup.get((c.text, d))\n",
        "            if not col:\n",
        "                continue\n",
        "            \n",
        "            arr = bitmap_arrays[col]\n",
        "            pos_idx = pos_by_dir[d]\n",
        "            neg_idx = neg_by_dir[d]\n",
        "            \n",
        "            if len(pos_idx) > 0:\n",
        "                pos_true += arr[pos_idx].sum()\n",
        "                pos_tot += len(pos_idx)\n",
        "            \n",
        "            if len(neg_idx) > 0:\n",
        "                neg_true += arr[neg_idx].sum()\n",
        "                neg_tot += len(neg_idx)\n",
        "        \n",
        "        if pos_tot <= 0 or neg_tot <= 0:\n",
        "            continue\n",
        "        \n",
        "        pos_rate = pos_true / pos_tot\n",
        "        neg_rate = neg_true / neg_tot\n",
        "        \n",
        "        # Filter by minimum support\n",
        "        if pos_rate < MIN_SUPPORT:\n",
        "            continue\n",
        "        \n",
        "        lift = compute_lift(pos_rate, neg_rate)\n",
        "        \n",
        "        # Filter by minimum lift\n",
        "        if lift < MIN_LIFT:\n",
        "            continue\n",
        "        \n",
        "        results.append((c.text, lift, pos_rate, neg_rate))\n",
        "    \n",
        "    # Sort by lift descending, then by pos_rate descending\n",
        "    results.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
        "    return results[:TOP_K_CRITERIA]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 66,927 learnable groups...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b28bf950ea6d4866acaa450f5e0aaf70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Scoring groups:   0%|          | 0/66927 [00:00<?, ?group/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processed 66,927 groups in 32.6m\n",
            "  Found 66,814 groups with discovered criteria\n",
            "  Rate: 34.2 groups/sec\n"
          ]
        }
      ],
      "source": [
        "# takes 32m\n",
        "# Process all learnable groups (FAST version using prefix_index)\n",
        "print(f\"Processing {learnable_groups.height:,} learnable groups...\")\n",
        "\n",
        "# learnable_groups = learnable_groups.head(100)  # Uncomment for testing\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "results: List[Dict[str, Any]] = []\n",
        "\n",
        "group_rows = learnable_groups.to_dicts()\n",
        "\n",
        "for i, g in enumerate(tqdm(group_rows, desc=\"Scoring groups\", unit=\"group\")):\n",
        "    prefix = g[\"prefix\"]\n",
        "    next_bid = g[\"next_bid\"]\n",
        "    seat = g[\"seat\"]\n",
        "    pos_count = g[\"pos_count\"]\n",
        "    neg_count = g[\"neg_count\"]\n",
        "    \n",
        "    # Score criteria using FAST O(1) lookup + numpy version\n",
        "    scored = score_criteria_for_group_fast(\n",
        "        prefix, next_bid,\n",
        "        prefix_index, bitmap_arrays, candidates, col_lookup\n",
        "    )\n",
        "    \n",
        "    if not scored:\n",
        "        continue\n",
        "    \n",
        "    # Build step auction string\n",
        "    step_auction = f\"{prefix}-{next_bid}\" if prefix else next_bid\n",
        "    \n",
        "    # Extract discovered criteria (names only)\n",
        "    discovered = [s[0] for s in scored]\n",
        "    \n",
        "    # Build criteria_with_metrics: list of dicts with full metrics for each criterion\n",
        "    # scored contains: (criterion_text, lift, pos_rate, neg_rate)\n",
        "    criteria_with_metrics = []\n",
        "    for s in scored:\n",
        "        lift_val = s[1]\n",
        "        # Handle infinity - store as None for JSON compatibility\n",
        "        if lift_val == float(\"inf\"):\n",
        "            lift_val = None\n",
        "        criteria_with_metrics.append({\n",
        "            \"criterion\": s[0],\n",
        "            \"lift\": lift_val,\n",
        "            \"pos_rate\": round(s[2], 4),\n",
        "            \"neg_rate\": round(s[3], 4),\n",
        "        })\n",
        "    \n",
        "    # Handle infinity in top_lift (use None for inf, Polars handles None properly)\n",
        "    raw_lift = scored[0][1] if scored else None\n",
        "    top_lift = None if raw_lift is None or raw_lift == float(\"inf\") else float(raw_lift)\n",
        "    \n",
        "    results.append({\n",
        "        \"prefix\": prefix,\n",
        "        \"next_bid\": next_bid,\n",
        "        \"step_auction\": step_auction,\n",
        "        \"seat\": seat,\n",
        "        \"pos_count\": pos_count,\n",
        "        \"neg_count\": neg_count,\n",
        "        \"discovered_criteria\": discovered,\n",
        "        \"criteria_with_metrics\": criteria_with_metrics,\n",
        "        \"top_lift\": top_lift,\n",
        "    })\n",
        "\n",
        "elapsed = time.perf_counter() - t0\n",
        "print(f\"  Processed {len(group_rows):,} groups in {fmt_elapsed(elapsed)}\")\n",
        "print(f\"  Found {len(results):,} groups with discovered criteria\")\n",
        "print(f\"  Rate: {len(group_rows)/elapsed:.1f} groups/sec\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preview of discovered criteria:\n",
            "shape: (20, 6)\n",
            "┌──────────────┬──────┬───────────┬───────────┬─────────────────────────────────┬───────────┐\n",
            "│ step_auction ┆ seat ┆ pos_count ┆ neg_count ┆ discovered_criteria             ┆ top_lift  │\n",
            "│ ---          ┆ ---  ┆ ---       ┆ ---       ┆ ---                             ┆ ---       │\n",
            "│ str          ┆ i64  ┆ i64       ┆ i64       ┆ list[str]                       ┆ f64       │\n",
            "╞══════════════╪══════╪═══════════╪═══════════╪═════════════════════════════════╪═══════════╡\n",
            "│ 1d           ┆ 1    ┆ 3507593   ┆ 12487234  ┆ [\"SL_D >= 6\", \"SL_D >= 5\", … \"… ┆ 8.140321  │\n",
            "│ 1c           ┆ 1    ┆ 3446023   ┆ 12548804  ┆ [\"SL_C >= 6\", \"SL_C >= 5\", … \"… ┆ 15.379386 │\n",
            "│ 1n           ┆ 1    ┆ 2518162   ┆ 13476665  ┆ [\"HCP >= 15\", \"HCP >= 16\", … \"… ┆ 2.641696  │\n",
            "│ 1s           ┆ 1    ┆ 2497723   ┆ 13497104  ┆ [\"SL_S >= 5\", \"SL_S >= 6\", … \"… ┆ 22.25641  │\n",
            "│ 1h           ┆ 1    ┆ 2363106   ┆ 13631721  ┆ [\"SL_H >= 5\", \"SL_H >= 6\", … \"… ┆ 18.684015 │\n",
            "│ …            ┆ …    ┆ …         ┆ …         ┆ …                               ┆ …         │\n",
            "│ 1d-p-1h-p    ┆ 4    ┆ 607804    ┆ 196429    ┆ [\"Total_Points <= 6\", \"Total_P… ┆ 21.184143 │\n",
            "│ 1c-p-1s      ┆ 3    ┆ 590588    ┆ 1314251   ┆ [\"SL_S >= 5\", \"SL_S >= 6\", … \"… ┆ 23.520155 │\n",
            "│ 1n-p-2c      ┆ 3    ┆ 590415    ┆ 1562009   ┆ [\"HCP >= 9\", \"HCP >= 8\", … \"HC… ┆ 2.131516  │\n",
            "│ 1n-p-2c-p    ┆ 4    ┆ 567114    ┆ 23301     ┆ [\"Total_Points <= 5\", \"Total_P… ┆ 32.377619 │\n",
            "│ 1n-p-p       ┆ 3    ┆ 560160    ┆ 1592264   ┆ [\"Total_Points <= 4\", \"Total_P… ┆ 9.020243  │\n",
            "└──────────────┴──────┴───────────┴───────────┴─────────────────────────────────┴───────────┘\n",
            "\n",
            "Criteria with metrics (first 5 rows):\n",
            "\n",
            "1d (seat 1):\n",
            "  SL_D >= 6             lift=  8.14  pos_rate=21.21%  neg_rate=2.61%\n",
            "  SL_D >= 5             lift=  6.98  pos_rate=56.52%  neg_rate=8.09%\n",
            "  SL_D >= 4             lift=  3.58  pos_rate=94.14%  neg_rate=26.29%\n",
            "  SL_D >= 3             lift=  1.64  pos_rate=99.35%  neg_rate=60.42%\n",
            "  SL_S <= 1             lift=  1.61  pos_rate=14.28%  neg_rate=8.84%\n",
            "  SL_H <= 1             lift=  1.59  pos_rate=14.37%  neg_rate=9.02%\n",
            "\n",
            "1c (seat 1):\n",
            "  SL_C >= 6             lift= 15.38  pos_rate=21.05%  neg_rate=1.37%\n",
            "  SL_C >= 5             lift=  6.86  pos_rate=52.26%  neg_rate=7.62%\n",
            "  SL_C >= 4             lift=  2.89  pos_rate=81.81%  neg_rate=28.32%\n",
            "  SL_C >= 3             lift=  1.65  pos_rate=98.60%  neg_rate=59.67%\n",
            "  SL_D <= 3             lift=  1.65  pos_rate=85.23%  neg_rate=51.58%\n",
            "  Total_Points <= 14    lift=  1.54  pos_rate=46.86%  neg_rate=30.34%\n",
            "\n",
            "1n (seat 1):\n",
            "  HCP >= 15             lift=  2.64  pos_rate=87.78%  neg_rate=33.23%\n",
            "  HCP >= 16             lift=  2.17  pos_rate=54.79%  neg_rate=25.29%\n",
            "  HCP >= 14             lift=  2.00  pos_rate=96.92%  neg_rate=48.43%\n",
            "  Total_Points >= 16    lift=  1.85  pos_rate=83.28%  neg_rate=45.13%\n",
            "  Total_Points >= 15    lift=  1.59  pos_rate=96.38%  neg_rate=60.44%\n",
            "  Total_Points >= 17    lift=  1.54  pos_rate=53.85%  neg_rate=34.93%\n",
            "\n",
            "1s (seat 1):\n",
            "  SL_S >= 5             lift= 22.26  pos_rate=99.32%  neg_rate=4.46%\n",
            "  SL_S >= 6             lift= 13.55  pos_rate=32.57%  neg_rate=2.40%\n",
            "  SL_S >= 4             lift=  3.23  pos_rate=99.93%  neg_rate=30.91%\n",
            "  SL_H <= 1             lift=  2.50  pos_rate=20.62%  neg_rate=8.26%\n",
            "  SL_D <= 1             lift=  2.40  pos_rate=20.15%  neg_rate=8.41%\n",
            "  SL_C <= 1             lift=  2.35  pos_rate=20.44%  neg_rate=8.71%\n",
            "\n",
            "1h (seat 1):\n",
            "  SL_H >= 5             lift= 18.68  pos_rate=99.16%  neg_rate=5.31%\n",
            "  SL_H >= 6             lift= 13.89  pos_rate=33.74%  neg_rate=2.43%\n",
            "  SL_H >= 4             lift=  3.21  pos_rate=99.92%  neg_rate=31.17%\n",
            "  SL_S <= 1             lift=  2.69  pos_rate=21.59%  neg_rate=8.03%\n",
            "  SL_D <= 1             lift=  2.17  pos_rate=18.93%  neg_rate=8.74%\n",
            "  SL_C <= 1             lift=  2.14  pos_rate=19.33%  neg_rate=9.02%\n"
          ]
        }
      ],
      "source": [
        "# Preview results\n",
        "print(\"Preview of discovered criteria:\")\n",
        "results_df = pl.DataFrame(results)\n",
        "print(results_df.select([\"step_auction\", \"seat\", \"pos_count\", \"neg_count\", \"discovered_criteria\", \"top_lift\"]).head(20))\n",
        "\n",
        "# Show criteria_with_metrics for first few rows\n",
        "print(\"\\nCriteria with metrics (first 5 rows):\")\n",
        "for i, row in enumerate(results[:5]):\n",
        "    print(f\"\\n{row['step_auction']} (seat {row['seat']}):\")\n",
        "    for m in row[\"criteria_with_metrics\"]:\n",
        "        lift_str = f\"{m['lift']:.2f}\" if m['lift'] is not None else \"inf\"\n",
        "        print(f\"  {m['criterion']:20s}  lift={lift_str:>6s}  pos_rate={m['pos_rate']:.2%}  neg_rate={m['neg_rate']:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 6: Merge with BT and Build New_Rules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing BT for join...\n",
            "  BT for join: 461,681,310 rows (deduped by auction) in 1.6h\n",
            "  Freed bt_df memory\n"
          ]
        }
      ],
      "source": [
        "# takes 100m\n",
        "# OPTIMIZED: Use Polars join instead of Python dict (461M iter_rows would take days!)\n",
        "# Just need: _auction_lower -> bt_index + Agg_Expr columns\n",
        "# BT has multiple rows per auction (different seats), so we must dedupe to avoid Cartesian explosion\n",
        "print(\"Preparing BT for join...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "# Select only columns we need, then dedupe by auction to get ONE row per unique auction\n",
        "# Use group_by().first() to get deterministic results (keeps first occurrence)\n",
        "bt_for_join = (\n",
        "    bt_df\n",
        "    .select([\"_auction_lower\", \"bt_index\"] + AGG_EXPR_COLS)\n",
        "#    .unique(subset=[\"_auction_lower\"]) # todo: benchmark this alternative.\n",
        "    .group_by(\"_auction_lower\")\n",
        "    .first()\n",
        ")\n",
        "\n",
        "# Free bt_df memory - no longer needed\n",
        "del bt_df\n",
        "gc.collect()\n",
        "\n",
        "print(f\"  BT for join: {bt_for_join.height:,} rows (deduped by auction) in {fmt_elapsed(time.perf_counter() - t0)}\")\n",
        "print(\"  Freed bt_df memory\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building New_Rules using vectorized operations...\n",
            "  Results: 66,814 rows\n",
            "  Joined: 66,814 rows, BT matches: 66,798\n",
            "  Built 66,814 New_Rules entries in 1.8m\n"
          ]
        }
      ],
      "source": [
        "# takes 2m\n",
        "# FULLY VECTORIZED: Use Polars expressions instead of Python loops\n",
        "print(\"Building New_Rules using vectorized operations...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "# Create DataFrame from results\n",
        "results_df = pl.DataFrame(results)\n",
        "print(f\"  Results: {results_df.height:,} rows\")\n",
        "\n",
        "# Add lowercase step_auction for join\n",
        "results_df = results_df.with_columns(\n",
        "    pl.col(\"step_auction\").str.to_lowercase().alias(\"_step_lower\")\n",
        ")\n",
        "\n",
        "# Join with BT to get bt_index and Agg_Expr columns\n",
        "joined = results_df.join(\n",
        "    bt_for_join,\n",
        "    left_on=\"_step_lower\",\n",
        "    right_on=\"_auction_lower\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "print(f\"  Joined: {joined.height:,} rows, BT matches: {joined['bt_index'].drop_nulls().len():,}\")\n",
        "\n",
        "# VECTORIZED: Select correct Agg_Expr column based on seat using pl.when()\n",
        "# Create base_rules column by selecting the right Agg_Expr_Seat_{seat} column\n",
        "final_df = joined.with_columns([\n",
        "    # Select base_rules based on seat (when bt_index is not null)\n",
        "    pl.when(pl.col(\"bt_index\").is_null())\n",
        "    .then(pl.lit(None).cast(pl.List(pl.Utf8)))\n",
        "    .when(pl.col(\"seat\") == 1).then(pl.col(\"Agg_Expr_Seat_1\"))\n",
        "    .when(pl.col(\"seat\") == 2).then(pl.col(\"Agg_Expr_Seat_2\"))\n",
        "    .when(pl.col(\"seat\") == 3).then(pl.col(\"Agg_Expr_Seat_3\"))\n",
        "    .when(pl.col(\"seat\") == 4).then(pl.col(\"Agg_Expr_Seat_4\"))\n",
        "    .otherwise(pl.lit(None).cast(pl.List(pl.Utf8)))\n",
        "    .alias(\"base_rules\"),\n",
        "    \n",
        "    # bt_row_found flag\n",
        "    pl.col(\"bt_index\").is_not_null().alias(\"bt_row_found\"),\n",
        "]).with_columns([\n",
        "    # Ensure base_rules is never null (use empty list instead)\n",
        "    pl.col(\"base_rules\").fill_null([]).alias(\"base_rules\"),\n",
        "]).with_columns([\n",
        "    # New_Rules = base_rules + discovered_criteria, then unique (preserves order in recent Polars)\n",
        "    pl.col(\"base_rules\").list.concat(pl.col(\"discovered_criteria\")).list.unique(maintain_order=True).alias(\"New_Rules\"),\n",
        "]).select([\n",
        "    # Final column selection\n",
        "    \"step_auction\",\n",
        "    \"bt_index\",\n",
        "    \"seat\",\n",
        "    \"prefix\",\n",
        "    \"next_bid\",\n",
        "    \"pos_count\",\n",
        "    \"neg_count\",\n",
        "    \"base_rules\",\n",
        "    pl.col(\"discovered_criteria\").alias(\"discovered_rules\"),\n",
        "    \"criteria_with_metrics\",\n",
        "    \"New_Rules\",\n",
        "    \"top_lift\",\n",
        "    \"bt_row_found\",\n",
        "])\n",
        "\n",
        "print(f\"  Built {final_df.height:,} New_Rules entries in {fmt_elapsed(time.perf_counter() - t0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sorting final DataFrame...\n",
            "Final DataFrame: (66814, 13)\n",
            "Columns: ['step_auction', 'bt_index', 'seat', 'prefix', 'next_bid', 'pos_count', 'neg_count', 'base_rules', 'discovered_rules', 'criteria_with_metrics', 'New_Rules', 'top_lift', 'bt_row_found']\n",
            "\n",
            "BT row found: 66,798 / 66,814\n"
          ]
        }
      ],
      "source": [
        "# Sort and inspect final DataFrame\n",
        "print(\"Sorting final DataFrame...\")\n",
        "\n",
        "# Sort by pos_count descending for easier inspection\n",
        "final_df = final_df.sort(\"pos_count\", descending=True)\n",
        "\n",
        "print(f\"Final DataFrame: {final_df.shape}\")\n",
        "print(f\"Columns: {final_df.columns}\")\n",
        "print(f\"\\nBT row found: {final_df['bt_row_found'].sum():,} / {final_df.height:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preview of final output:\n",
            "shape: (30, 8)\n",
            "┌─────────────┬───────────┬──────┬───────────┬─────────────┬─────────────┬─────────────┬───────────┐\n",
            "│ step_auctio ┆ bt_index  ┆ seat ┆ pos_count ┆ base_rules  ┆ discovered_ ┆ New_Rules   ┆ top_lift  │\n",
            "│ n           ┆ ---       ┆ ---  ┆ ---       ┆ ---         ┆ rules       ┆ ---         ┆ ---       │\n",
            "│ ---         ┆ u32       ┆ i64  ┆ i64       ┆ list[str]   ┆ ---         ┆ list[str]   ┆ f64       │\n",
            "│ str         ┆           ┆      ┆           ┆             ┆ list[str]   ┆             ┆           │\n",
            "╞═════════════╪═══════════╪══════╪═══════════╪═════════════╪═════════════╪═════════════╪═══════════╡\n",
            "│ 1d          ┆ 151867501 ┆ 1    ┆ 3507593   ┆ [\"HCP <=    ┆ [\"SL_D >=   ┆ [\"HCP <=    ┆ 8.140321  │\n",
            "│             ┆           ┆      ┆           ┆ 21\", \"HCP   ┆ 6\", \"SL_D   ┆ 21\", \"HCP   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ >= 11\", …   ┆ >= 5\", … \"… ┆ >= 11\", …   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ \"…          ┆             ┆ \"…          ┆           │\n",
            "│ 1c          ┆ 0         ┆ 1    ┆ 3446023   ┆ [\"HCP <=    ┆ [\"SL_C >=   ┆ [\"HCP <=    ┆ 15.379386 │\n",
            "│             ┆           ┆      ┆           ┆ 21\", \"HCP   ┆ 6\", \"SL_C   ┆ 21\", \"HCP   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ >= 11\", …   ┆ >= 5\", … \"… ┆ >= 11\", …   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ \"…          ┆             ┆ \"…          ┆           │\n",
            "│ 1n          ┆ 408062490 ┆ 1    ┆ 2518162   ┆ [\"HCP <=    ┆ [\"HCP >=    ┆ [\"HCP <=    ┆ 2.641696  │\n",
            "│             ┆           ┆      ┆           ┆ 17\", \"HCP   ┆ 15\", \"HCP   ┆ 17\", \"HCP   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ >= 15\", …   ┆ >= 16\", …   ┆ >= 15\", …   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ \"…          ┆ \"…          ┆ \"…          ┆           │\n",
            "│ 1s          ┆ 351032258 ┆ 1    ┆ 2497723   ┆ [\"HCP <=    ┆ [\"SL_S >=   ┆ [\"HCP <=    ┆ 22.25641  │\n",
            "│             ┆           ┆      ┆           ┆ 21\", \"HCP   ┆ 5\", \"SL_S   ┆ 21\", \"HCP   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ >= 11\", …   ┆ >= 6\", … \"… ┆ >= 11\", …   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ \"…          ┆             ┆ \"…          ┆           │\n",
            "│ 1h          ┆ 280296284 ┆ 1    ┆ 2363106   ┆ [\"HCP <=    ┆ [\"SL_H >=   ┆ [\"HCP <=    ┆ 18.684015 │\n",
            "│             ┆           ┆      ┆           ┆ 21\", \"HCP   ┆ 5\", \"SL_H   ┆ 21\", \"HCP   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ >= 11\", …   ┆ >= 6\", … \"… ┆ >= 11\", …   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ \"…          ┆             ┆ \"…          ┆           │\n",
            "│ …           ┆ …         ┆ …    ┆ …         ┆ …           ┆ …           ┆ …           ┆ …         │\n",
            "│ 2n-p        ┆ 456166979 ┆ 2    ┆ 475612    ┆ [\"Total_Poi ┆ [\"Total_Poi ┆ [\"Total_Poi ┆ null      │\n",
            "│             ┆           ┆      ┆           ┆ nts <= 20\"] ┆ nts <= 4\",  ┆ nts <= 20\", ┆           │\n",
            "│             ┆           ┆      ┆           ┆             ┆ \"Total_P…   ┆ \"Total_…    ┆           │\n",
            "│ 1c-p-1s-p   ┆ 129596304 ┆ 4    ┆ 474537    ┆ [\"Total_Poi ┆ [\"Total_Poi ┆ [\"Total_Poi ┆ 90.690264 │\n",
            "│             ┆           ┆      ┆           ┆ nts <= 20\"] ┆ nts <= 6\",  ┆ nts <= 20\", ┆           │\n",
            "│             ┆           ┆      ┆           ┆             ┆ \"Total_P…   ┆ \"Total_…    ┆           │\n",
            "│ 1h-p-1s-p   ┆ 327885685 ┆ 4    ┆ 450891    ┆ [\"Total_Poi ┆ [\"Total_Poi ┆ [\"Total_Poi ┆ 42.830037 │\n",
            "│             ┆           ┆      ┆           ┆ nts <= 20\"] ┆ nts <= 6\",  ┆ nts <= 20\", ┆           │\n",
            "│             ┆           ┆      ┆           ┆             ┆ \"Total_P…   ┆ \"Total_…    ┆           │\n",
            "│ 1d-1s       ┆ 175043574 ┆ 2    ┆ 387100    ┆ [\"HCP <=    ┆ [\"SL_S >=   ┆ [\"HCP <=    ┆ 8.601429  │\n",
            "│             ┆           ┆      ┆           ┆ 17\", \"HCP   ┆ 5\", \"SL_S   ┆ 17\", \"HCP   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ >= 8\", …    ┆ >= 6\", … \"… ┆ >= 8\", …    ┆           │\n",
            "│             ┆           ┆      ┆           ┆ \"T…         ┆             ┆ \"T…         ┆           │\n",
            "│ 1d-1h       ┆ 151867502 ┆ 2    ┆ 376280    ┆ [\"HCP <=    ┆ [\"SL_H >=   ┆ [\"HCP <=    ┆ 8.183488  │\n",
            "│             ┆           ┆      ┆           ┆ 17\", \"HCP   ┆ 5\", \"SL_H   ┆ 17\", \"HCP   ┆           │\n",
            "│             ┆           ┆      ┆           ┆ >= 8\", …    ┆ >= 6\", … \"… ┆ >= 8\", …    ┆           │\n",
            "│             ┆           ┆      ┆           ┆ \"T…         ┆             ┆ \"S…         ┆           │\n",
            "└─────────────┴───────────┴──────┴───────────┴─────────────┴─────────────┴─────────────┴───────────┘\n"
          ]
        }
      ],
      "source": [
        "# Preview\n",
        "print(\"Preview of final output:\")\n",
        "display_cols = [\"step_auction\", \"bt_index\", \"seat\", \"pos_count\", \"base_rules\", \"discovered_rules\", \"New_Rules\", \"top_lift\"]\n",
        "print(final_df.select([c for c in display_cols if c in final_df.columns]).head(30))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 7: Save Output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving to E:\\bridge\\data\\bbo\\bidding\\bbo_bt_new_rules.parquet...\n",
            "  Saved 66,814 rows to E:\\bridge\\data\\bbo\\bidding\\bbo_bt_new_rules.parquet\n",
            "  File size: 8.80 MB\n",
            "  Time: 0.3s\n"
          ]
        }
      ],
      "source": [
        "# takes 0s\n",
        "# Save to parquet\n",
        "print(f\"Saving to {OUTPUT_FILE}...\")\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "final_df.write_parquet(OUTPUT_FILE)\n",
        "\n",
        "file_size_mb = OUTPUT_FILE.stat().st_size / (1024 * 1024)\n",
        "print(f\"  Saved {final_df.height:,} rows to {OUTPUT_FILE}\")\n",
        "print(f\"  File size: {file_size_mb:.2f} MB\")\n",
        "print(f\"  Time: {fmt_elapsed(time.perf_counter() - t0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SUMMARY\n",
            "============================================================\n",
            "Unique (prefix, next_bid) groups: 4,172,691\n",
            "Learnable groups (>= 100 pos): 66,927\n",
            "Groups with discovered criteria: 66,814\n",
            "Final New_Rules entries: 66,814\n",
            "  - With BT row: 66,798\n",
            "  - Without BT row: 16\n",
            "\n",
            "Output file: E:\\bridge\\data\\bbo\\bidding\\bbo_bt_new_rules.parquet\n",
            "File size: 8.80 MB\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "#print(f\"Deals processed: {deals_df.height:,}\")\n",
        "print(f\"Unique (prefix, next_bid) groups: {group_counts.height:,}\")\n",
        "print(f\"Learnable groups (>= {MIN_POS_SAMPLES} pos): {learnable_groups.height:,}\")\n",
        "print(f\"Groups with discovered criteria: {len(results):,}\")\n",
        "print(f\"Final New_Rules entries: {final_df.height:,}\")\n",
        "print(f\"  - With BT row: {final_df['bt_row_found'].sum():,}\")\n",
        "print(f\"  - Without BT row: {(~final_df['bt_row_found']).sum():,}\")\n",
        "print(f\"\\nOutput file: {OUTPUT_FILE}\")\n",
        "print(f\"File size: {file_size_mb:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribution of discovered criteria count per step:\n",
            "shape: (6, 2)\n",
            "┌──────────────┬───────┐\n",
            "│ n_discovered ┆ count │\n",
            "│ ---          ┆ ---   │\n",
            "│ u64          ┆ u64   │\n",
            "╞══════════════╪═══════╡\n",
            "│ 1            ┆ 227   │\n",
            "│ 2            ┆ 340   │\n",
            "│ 3            ┆ 576   │\n",
            "│ 4            ┆ 879   │\n",
            "│ 5            ┆ 1212  │\n",
            "│ 6            ┆ 63580 │\n",
            "└──────────────┴───────┘\n"
          ]
        }
      ],
      "source": [
        "# Distribution of discovered criteria count\n",
        "print(\"\\nDistribution of discovered criteria count per step:\")\n",
        "discovered_counts = final_df.select(\n",
        "    pl.col(\"discovered_rules\").list.len().alias(\"n_discovered\")\n",
        ").group_by(\"n_discovered\").agg(pl.len().alias(\"count\")).sort(\"n_discovered\")\n",
        "print(discovered_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 20 most frequently discovered criteria:\n",
            "shape: (20, 2)\n",
            "┌────────────────────┬───────┐\n",
            "│ criterion          ┆ count │\n",
            "│ ---                ┆ ---   │\n",
            "│ str                ┆ u64   │\n",
            "╞════════════════════╪═══════╡\n",
            "│ Total_Points <= 13 ┆ 12841 │\n",
            "│ Total_Points <= 14 ┆ 11367 │\n",
            "│ HCP <= 11          ┆ 10627 │\n",
            "│ HCP <= 12          ┆ 10042 │\n",
            "│ Total_Points <= 12 ┆ 9312  │\n",
            "│ …                  ┆ …     │\n",
            "│ HCP <= 8           ┆ 5430  │\n",
            "│ SL_D >= 4          ┆ 5376  │\n",
            "│ SL_H >= 4          ┆ 5348  │\n",
            "│ SL_S <= 2          ┆ 5328  │\n",
            "│ SL_C <= 1          ┆ 5293  │\n",
            "└────────────────────┴───────┘\n"
          ]
        }
      ],
      "source": [
        "# Top discovered criteria overall\n",
        "print(\"\\nTop 20 most frequently discovered criteria:\")\n",
        "all_discovered = final_df.select(pl.col(\"discovered_rules\").explode().alias(\"criterion\")).drop_nulls()\n",
        "crit_counts = all_discovered.group_by(\"criterion\").agg(pl.len().alias(\"count\")).sort(\"count\", descending=True)\n",
        "print(crit_counts.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Lift distribution (top_lift):\n",
            "shape: (9, 2)\n",
            "┌────────────┬─────────────┐\n",
            "│ statistic  ┆ top_lift    │\n",
            "│ ---        ┆ ---         │\n",
            "│ str        ┆ f64         │\n",
            "╞════════════╪═════════════╡\n",
            "│ count      ┆ 37214.0     │\n",
            "│ null_count ┆ 29600.0     │\n",
            "│ mean       ┆ 46.45303    │\n",
            "│ std        ┆ 780.979983  │\n",
            "│ min        ┆ 1.300221    │\n",
            "│ 25%        ┆ 3.665746    │\n",
            "│ 50%        ┆ 7.025837    │\n",
            "│ 75%        ┆ 16.557446   │\n",
            "│ max        ┆ 89302.37548 │\n",
            "└────────────┴─────────────┘\n"
          ]
        }
      ],
      "source": [
        "# Lift distribution\n",
        "print(\"\\nLift distribution (top_lift):\")\n",
        "lift_stats = final_df.select(pl.col(\"top_lift\")).describe()\n",
        "print(lift_stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Inspection\n",
        "\n",
        "Inspect some specific cases to validate the discovered rules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Opening bids (prefix=''):\n",
            "shape: (15, 5)\n",
            "┌──────────────┬───────────┬─────────────────────────────┬─────────────────────────────┬───────────┐\n",
            "│ step_auction ┆ pos_count ┆ base_rules                  ┆ discovered_rules            ┆ top_lift  │\n",
            "│ ---          ┆ ---       ┆ ---                         ┆ ---                         ┆ ---       │\n",
            "│ str          ┆ i64       ┆ list[str]                   ┆ list[str]                   ┆ f64       │\n",
            "╞══════════════╪═══════════╪═════════════════════════════╪═════════════════════════════╪═══════════╡\n",
            "│ 1d           ┆ 3507593   ┆ [\"HCP <= 21\", \"HCP >= 11\",  ┆ [\"SL_D >= 6\", \"SL_D >= 5\",  ┆ 8.140321  │\n",
            "│              ┆           ┆ … \"…                        ┆ … \"…                        ┆           │\n",
            "│ 1c           ┆ 3446023   ┆ [\"HCP <= 21\", \"HCP >= 11\",  ┆ [\"SL_C >= 6\", \"SL_C >= 5\",  ┆ 15.379386 │\n",
            "│              ┆           ┆ … \"…                        ┆ … \"…                        ┆           │\n",
            "│ 1n           ┆ 2518162   ┆ [\"HCP <= 17\", \"HCP >= 15\",  ┆ [\"HCP >= 15\", \"HCP >= 16\",  ┆ 2.641696  │\n",
            "│              ┆           ┆ … \"…                        ┆ … \"…                        ┆           │\n",
            "│ 1s           ┆ 2497723   ┆ [\"HCP <= 21\", \"HCP >= 11\",  ┆ [\"SL_S >= 5\", \"SL_S >= 6\",  ┆ 22.25641  │\n",
            "│              ┆           ┆ … \"…                        ┆ … \"…                        ┆           │\n",
            "│ 1h           ┆ 2363106   ┆ [\"HCP <= 21\", \"HCP >= 11\",  ┆ [\"SL_H >= 5\", \"SL_H >= 6\",  ┆ 18.684015 │\n",
            "│              ┆           ┆ … \"…                        ┆ … \"…                        ┆           │\n",
            "│ …            ┆ …         ┆ …                           ┆ …                           ┆ …         │\n",
            "│ 3c           ┆ 53699     ┆ [\"C_CQ == False\", \"HCP <=   ┆ [\"SL_C >= 7\", \"HCP <= 6\", … ┆ 85.423058 │\n",
            "│              ┆           ┆ 9\", …                       ┆ \"T…                         ┆           │\n",
            "│ 3d           ┆ 49284     ┆ [\"C_DQ == False\", \"HCP <=   ┆ [\"SL_D >= 7\", \"HCP <= 6\", … ┆ 87.642399 │\n",
            "│              ┆           ┆ 9\", …                       ┆ \"T…                         ┆           │\n",
            "│ 3h           ┆ 48915     ┆ [\"C_HQ == False\", \"HCP <=   ┆ [\"SL_H >= 7\", \"HCP <= 6\", … ┆ 82.007436 │\n",
            "│              ┆           ┆ 9\", …                       ┆ \"T…                         ┆           │\n",
            "│ 3s           ┆ 48697     ┆ [\"C_SQ == False\", \"HCP <=   ┆ [\"SL_S >= 7\", \"HCP <= 6\", … ┆ 81.635204 │\n",
            "│              ┆           ┆ 9\", …                       ┆ \"T…                         ┆           │\n",
            "│ 4h           ┆ 48090     ┆ [\"HCP <= 9\", \"HCP >= 5\",    ┆ [\"SL_H >= 8\", \"SL_H >= 7\",  ┆ 294.7447  │\n",
            "│              ┆           ┆ \"SL_H…                      ┆ … \"…                        ┆           │\n",
            "└──────────────┴───────────┴─────────────────────────────┴─────────────────────────────┴───────────┘\n"
          ]
        }
      ],
      "source": [
        "# Inspect opening bids (most common)\n",
        "print(\"Opening bids (prefix=''):\")\n",
        "openings = final_df.filter(pl.col(\"prefix\") == \"\").sort(\"pos_count\", descending=True)\n",
        "print(openings.select([\"step_auction\", \"pos_count\", \"base_rules\", \"discovered_rules\", \"top_lift\"]).head(15))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Responses after 1N:\n",
            "shape: (15, 5)\n",
            "┌──────────────┬───────────┬────────────────────────────┬────────────────────────────┬─────────────┐\n",
            "│ step_auction ┆ pos_count ┆ base_rules                 ┆ discovered_rules           ┆ top_lift    │\n",
            "│ ---          ┆ ---       ┆ ---                        ┆ ---                        ┆ ---         │\n",
            "│ str          ┆ i64       ┆ list[str]                  ┆ list[str]                  ┆ f64         │\n",
            "╞══════════════╪═══════════╪════════════════════════════╪════════════════════════════╪═════════════╡\n",
            "│ 1n-p         ┆ 2152534   ┆ [\"Total_Points <= 20\"]     ┆ [\"Total_Points <= 5\",      ┆ 3779.71546  │\n",
            "│              ┆           ┆                            ┆ \"Total_P…                  ┆             │\n",
            "│ 1n-2c        ┆ 143828    ┆ [\"HCP <= 14\",              ┆ [\"SL_C >= 6\", \"SL_D >= 6\", ┆ 9.41197     │\n",
            "│              ┆           ┆ \"Total_Points >=…          ┆ … \"…                       ┆             │\n",
            "│ 1n-2s        ┆ 60051     ┆ [\"SL_H <= 3\", \"SL_S >= 4\", ┆ [\"SL_H <= 1\",              ┆ 6.192528    │\n",
            "│              ┆           ┆ \"To…                       ┆ \"Total_Points >=…          ┆             │\n",
            "│ 1n-2h        ┆ 58152     ┆ [\"SL_H >= 4\", \"SL_S <= 3\", ┆ [\"SL_S <= 1\",              ┆ 5.965044    │\n",
            "│              ┆           ┆ \"To…                       ┆ \"Total_Points >=…          ┆             │\n",
            "│ 1n-2d        ┆ 50700     ┆ [\"SL_H >= 5\", \"SL_S >= 5\", ┆ [\"SL_D <= 1\", \"SL_C <= 1\", ┆ 5.223484    │\n",
            "│              ┆           ┆ \"To…                       ┆ … \"…                       ┆             │\n",
            "│ …            ┆ …         ┆ …                          ┆ …                          ┆ …           │\n",
            "│ 1n-2n        ┆ 2679      ┆ [\"SL_C >= 5\", \"SL_D >= 5\", ┆ [\"Total_Points >= 16\",     ┆ 16.686909   │\n",
            "│              ┆           ┆ \"To…                       ┆ \"Total_…                   ┆             │\n",
            "│ 1n-4h        ┆ 475       ┆ [\"HCP <= 11\", \"SL_H >= 7\", ┆ [\"SL_H >= 8\",              ┆ 1216.518181 │\n",
            "│              ┆           ┆ \"To…                       ┆ \"Total_Points >=…          ┆             │\n",
            "│ 1n-4s        ┆ 358       ┆ [\"HCP <= 11\", \"SL_S >= 7\", ┆ [\"SL_S >= 8\",              ┆ 895.594513  │\n",
            "│              ┆           ┆ \"To…                       ┆ \"Total_Points >=…          ┆             │\n",
            "│ 1n-4c        ┆ 238       ┆ [\"HCP <= 11\", \"SL_C >= 7\", ┆ [\"SL_C >= 8\", \"SL_C >= 7\", ┆ 1771.90594  │\n",
            "│              ┆           ┆ \"To…                       ┆ … \"…                       ┆             │\n",
            "│ 1n-4d        ┆ 174       ┆ [\"HCP <= 11\", \"SL_D >= 7\", ┆ [\"SL_D >= 8\", \"SL_D >= 7\", ┆ 1499.027366 │\n",
            "│              ┆           ┆ \"To…                       ┆ … \"…                       ┆             │\n",
            "└──────────────┴───────────┴────────────────────────────┴────────────────────────────┴─────────────┘\n"
          ]
        }
      ],
      "source": [
        "# Inspect responses to 1NT\n",
        "print(\"Responses after 1N:\")\n",
        "resp_1n = final_df.filter(pl.col(\"prefix\") == \"1n\").sort(\"pos_count\", descending=True)\n",
        "print(resp_1n.select([\"step_auction\", \"pos_count\", \"base_rules\", \"discovered_rules\", \"top_lift\"]).head(15))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Responses after 1S:\n",
            "shape: (15, 5)\n",
            "┌──────────────┬───────────┬────────────────────────────┬────────────────────────────┬─────────────┐\n",
            "│ step_auction ┆ pos_count ┆ base_rules                 ┆ discovered_rules           ┆ top_lift    │\n",
            "│ ---          ┆ ---       ┆ ---                        ┆ ---                        ┆ ---         │\n",
            "│ str          ┆ i64       ┆ list[str]                  ┆ list[str]                  ┆ f64         │\n",
            "╞══════════════╪═══════════╪════════════════════════════╪════════════════════════════╪═════════════╡\n",
            "│ 1s-p         ┆ 1808043   ┆ [\"Total_Points <= 16\"]     ┆ [\"Total_Points <= 6\",      ┆ 92.60118    │\n",
            "│              ┆           ┆                            ┆ \"Total_P…                  ┆             │\n",
            "│ 1s-2h        ┆ 142001    ┆ [\"HCP >= 10\", \"SL_H >= 5\", ┆ [\"SL_H >= 6\", \"SL_H >= 5\", ┆ 8.5488      │\n",
            "│              ┆           ┆ … \"…                       ┆ … \"…                       ┆             │\n",
            "│ 1s-d         ┆ 138312    ┆ [\"SL_C <= 5\", \"SL_C >= 3\", ┆ [\"HCP >= 18\",              ┆ 16.215184   │\n",
            "│              ┆           ┆ … \"…                       ┆ \"Total_Points >=…          ┆             │\n",
            "│ 1s-2d        ┆ 120428    ┆ [\"HCP >= 10\", \"SL_D >= 5\", ┆ [\"SL_D >= 6\", \"SL_D >= 5\", ┆ 10.346469   │\n",
            "│              ┆           ┆ … \"…                       ┆ … \"…                       ┆             │\n",
            "│ 1s-2c        ┆ 119108    ┆ [\"HCP >= 10\", \"SL_C >= 5\", ┆ [\"SL_C >= 6\", \"SL_C >= 5\", ┆ 10.314008   │\n",
            "│              ┆           ┆ … \"…                       ┆ … \"…                       ┆             │\n",
            "│ …            ┆ …         ┆ …                          ┆ …                          ┆ …           │\n",
            "│ 1s-2n        ┆ 13738     ┆ [\"Forcing_One_Round\",      ┆ [\"SL_H <= 1\",              ┆ 7.559277    │\n",
            "│              ┆           ┆ \"SL_C >=…                  ┆ \"Total_Points >=…          ┆             │\n",
            "│ 1s-4h        ┆ 7169      ┆ [\"HCP <= 11\", \"SL_H >= 7\", ┆ [\"SL_H >= 8\", \"SL_H >= 7\", ┆ 942.054341  │\n",
            "│              ┆           ┆ \"To…                       ┆ … \"…                       ┆             │\n",
            "│ 1s-4c        ┆ 3226      ┆ [\"HCP <= 11\", \"SL_C >= 7\", ┆ [\"SL_C >= 9\", \"SL_C >= 8\", ┆ 1597.581086 │\n",
            "│              ┆           ┆ \"To…                       ┆ … \"…                       ┆             │\n",
            "│ 1s-4d        ┆ 2865      ┆ [\"HCP <= 11\", \"SL_D >= 7\", ┆ [\"SL_D >= 8\", \"SL_D >= 7\", ┆ 1191.680203 │\n",
            "│              ┆           ┆ \"To…                       ┆ … \"…                       ┆             │\n",
            "│ 1s-3n        ┆ 673       ┆ [\"HCP <= 32\", \"HCP >= 25\", ┆ [\"HCP >= 22\", \"HCP >= 21\", ┆ 251.993739  │\n",
            "│              ┆           ┆ … \"…                       ┆ … \"…                       ┆             │\n",
            "└──────────────┴───────────┴────────────────────────────┴────────────────────────────┴─────────────┘\n"
          ]
        }
      ],
      "source": [
        "# Inspect responses to 1S\n",
        "print(\"Responses after 1S:\")\n",
        "resp_1s = final_df.filter(pl.col(\"prefix\") == \"1s\").sort(\"pos_count\", descending=True)\n",
        "print(resp_1s.select([\"step_auction\", \"pos_count\", \"base_rules\", \"discovered_rules\", \"top_lift\"]).head(15))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 highest lift cases:\n",
            "shape: (20, 4)\n",
            "┌───────────────────┬───────────┬─────────────────────────────────┬──────────────┐\n",
            "│ step_auction      ┆ pos_count ┆ discovered_rules                ┆ top_lift     │\n",
            "│ ---               ┆ ---       ┆ ---                             ┆ ---          │\n",
            "│ str               ┆ i64       ┆ list[str]                       ┆ f64          │\n",
            "╞═══════════════════╪═══════════╪═════════════════════════════════╪══════════════╡\n",
            "│ 1d-p-p            ┆ 151180    ┆ [\"Total_Points <= 3\", \"Total_P… ┆ 89302.37548  │\n",
            "│ 1c-1d-p           ┆ 53032     ┆ [\"Total_Points <= 3\", \"HCP <= … ┆ 63221.987668 │\n",
            "│ 1c-p-p            ┆ 123297    ┆ [\"Total_Points <= 4\", \"Total_P… ┆ 40161.908819 │\n",
            "│ 2n-p-3h-p-3s-p-4h ┆ 1599      ┆ [\"SL_H >= 5\", \"SL_H >= 4\", … \"… ┆ 38422.477799 │\n",
            "│ 1d-1s-p           ┆ 103900    ┆ [\"Total_Points <= 3\", \"Total_P… ┆ 37493.814822 │\n",
            "│ …                 ┆ …         ┆ …                               ┆ …            │\n",
            "│ 1d-3d             ┆ 2106      ┆ [\"SL_D >= 8\", \"SL_D >= 7\", … \"… ┆ 11775.344917 │\n",
            "│ 1s-p-1n-p-2h-p-2s ┆ 25784     ┆ [\"Total_Points <= 6\", \"HCP <= … ┆ 11096.444307 │\n",
            "│ 1n-p-2d-p-2h-p-2s ┆ 4558      ┆ [\"SL_S >= 6\", \"SL_S >= 5\", … \"… ┆ 10951.869022 │\n",
            "│ 2c-p-2d-p-2n-p-4d ┆ 3112      ┆ [\"SL_H >= 7\", \"SL_H >= 6\", … \"… ┆ 10217.415167 │\n",
            "│ 2n-p-3c-p-3d-p-3h ┆ 4679      ┆ [\"SL_S >= 5\", \"SL_C <= 1\", … \"… ┆ 9616.663532  │\n",
            "└───────────────────┴───────────┴─────────────────────────────────┴──────────────┘\n"
          ]
        }
      ],
      "source": [
        "# High lift cases (most discriminative criteria)\n",
        "# Note: top_lift is None for infinite lift (neg_rate was 0)\n",
        "print(\"Top 20 highest lift cases:\")\n",
        "high_lift = final_df.filter(pl.col(\"top_lift\").is_not_null()).sort(\"top_lift\", descending=True)\n",
        "print(high_lift.select([\"step_auction\", \"pos_count\", \"discovered_rules\", \"top_lift\"]).head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inspecting criteria_with_metrics for selected auctions:\n",
            "================================================================================\n",
            "\n",
            "1n (seat 1, 2,518,162 deals):\n",
            "  Base rules: ['HCP <= 17', 'HCP >= 15', 'SL_C <= 5', 'SL_C >= 2', 'SL_D <= 5', 'SL_D >= 2', 'SL_H <= 5', 'SL_H >= 2', 'SL_S <= 5', 'SL_S >= 2', 'Total_Points <= 18']\n",
            "  Discovered criteria with metrics:\n",
            "    HCP >= 15                  lift=    2.64  pos=87.78%  neg=33.23%\n",
            "    HCP >= 16                  lift=    2.17  pos=54.79%  neg=25.29%\n",
            "    HCP >= 14                  lift=    2.00  pos=96.92%  neg=48.43%\n",
            "    Total_Points >= 16         lift=    1.85  pos=83.28%  neg=45.13%\n",
            "    Total_Points >= 15         lift=    1.59  pos=96.38%  neg=60.44%\n",
            "    Total_Points >= 17         lift=    1.54  pos=53.85%  neg=34.93%\n",
            "\n",
            "1s (seat 1, 2,497,723 deals):\n",
            "  Base rules: ['HCP <= 21', 'HCP >= 11', 'SL_S >= 5', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Discovered criteria with metrics:\n",
            "    SL_S >= 5                  lift=   22.26  pos=99.32%  neg= 4.46%\n",
            "    SL_S >= 6                  lift=   13.55  pos=32.57%  neg= 2.40%\n",
            "    SL_S >= 4                  lift=    3.23  pos=99.93%  neg=30.91%\n",
            "    SL_H <= 1                  lift=    2.50  pos=20.62%  neg= 8.26%\n",
            "    SL_D <= 1                  lift=    2.40  pos=20.15%  neg= 8.41%\n",
            "    SL_C <= 1                  lift=    2.35  pos=20.44%  neg= 8.71%\n",
            "\n",
            "1h (seat 1, 2,363,106 deals):\n",
            "  Base rules: ['HCP <= 21', 'HCP >= 11', 'SL_H >= 5', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Discovered criteria with metrics:\n",
            "    SL_H >= 5                  lift=   18.68  pos=99.16%  neg= 5.31%\n",
            "    SL_H >= 6                  lift=   13.89  pos=33.74%  neg= 2.43%\n",
            "    SL_H >= 4                  lift=    3.21  pos=99.92%  neg=31.17%\n",
            "    SL_S <= 1                  lift=    2.69  pos=21.59%  neg= 8.03%\n",
            "    SL_D <= 1                  lift=    2.17  pos=18.93%  neg= 8.74%\n",
            "    SL_C <= 1                  lift=    2.14  pos=19.33%  neg= 9.02%\n",
            "\n",
            "1d (seat 1, 3,507,593 deals):\n",
            "  Base rules: ['HCP <= 21', 'HCP >= 11', 'SL_D >= 3', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Discovered criteria with metrics:\n",
            "    SL_D >= 6                  lift=    8.14  pos=21.21%  neg= 2.61%\n",
            "    SL_D >= 5                  lift=    6.98  pos=56.52%  neg= 8.09%\n",
            "    SL_D >= 4                  lift=    3.58  pos=94.14%  neg=26.29%\n",
            "    SL_D >= 3                  lift=    1.64  pos=99.35%  neg=60.42%\n",
            "    SL_S <= 1                  lift=    1.61  pos=14.28%  neg= 8.84%\n",
            "    SL_H <= 1                  lift=    1.59  pos=14.37%  neg= 9.02%\n",
            "\n",
            "1c (seat 1, 3,446,023 deals):\n",
            "  Base rules: ['HCP <= 21', 'HCP >= 11', 'SL_C >= 3', 'Total_Points <= 22', 'Total_Points >= 12']\n",
            "  Discovered criteria with metrics:\n",
            "    SL_C >= 6                  lift=   15.38  pos=21.05%  neg= 1.37%\n",
            "    SL_C >= 5                  lift=    6.86  pos=52.26%  neg= 7.62%\n",
            "    SL_C >= 4                  lift=    2.89  pos=81.81%  neg=28.32%\n",
            "    SL_C >= 3                  lift=    1.65  pos=98.60%  neg=59.67%\n",
            "    SL_D <= 3                  lift=    1.65  pos=85.23%  neg=51.58%\n",
            "    Total_Points <= 14         lift=    1.54  pos=46.86%  neg=30.34%\n"
          ]
        }
      ],
      "source": [
        "# Inspect criteria_with_metrics for detailed analysis\n",
        "# This column allows you to examine each criterion's lift, pos_rate, and neg_rate\n",
        "# to decide whether to include/exclude it from New_Rules\n",
        "\n",
        "print(\"Inspecting criteria_with_metrics for selected auctions:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Example: Look at a common opening bid\n",
        "sample_auctions = [\"1n\", \"1s\", \"1h\", \"1d\", \"1c\"]\n",
        "for auc in sample_auctions:\n",
        "    row = final_df.filter(pl.col(\"step_auction\") == auc).to_dicts()\n",
        "    if row:\n",
        "        row = row[0]\n",
        "        print(f\"\\n{auc} (seat {row['seat']}, {row['pos_count']:,} deals):\")\n",
        "        print(f\"  Base rules: {row['base_rules']}\")\n",
        "        print(f\"  Discovered criteria with metrics:\")\n",
        "        for m in row[\"criteria_with_metrics\"]:\n",
        "            lift_str = f\"{m['lift']:.2f}\" if m['lift'] is not None else \"inf\"\n",
        "            print(f\"    {m['criterion']:25s}  lift={lift_str:>8s}  pos={m['pos_rate']:>6.2%}  neg={m['neg_rate']:>6.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Program elapsed time in seconds: 10604.69614315033\n",
            "2025-12-27 15:03:34\n"
          ]
        }
      ],
      "source": [
        "print('Program elapsed time in seconds:', time.time()-program_start_time)\n",
        "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
